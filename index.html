<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>АТестирование ПО - Полное руководство.</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header class="header">
            <h1 class="main-title">Тестирование ПО</h1>
            <p class="subtitle">Современное руководство по QA и тестированию</p>
            <P>Автор: FAZKEK | Дата: Октябрь 2025</P>
        </header>

        <nav class="navigation">
            <div class="nav-container">
                <button class="nav-toggle" id="navToggle">☰</button>
                <ul class="nav-menu" id="navMenu">
                    <li><a href="#stlc" class="nav-link">STLC</a></li>
                    <li><a href="#principles" class="nav-link">Принципы тестирования</a></li>
                    <li><a href="#requirements" class="nav-link">Требования</a></li>
                    <li><a href="#metrics" class="nav-link">Метрики</a></li>
                    <li><a href="#testing-types" class="nav-link">Виды тестирования</a></li>
                    <li><a href="#test-design" class="nav-link">Тест-дизайн</a></li>
                    <li><a href="#bug-reports" class="nav-link">Баг-репорты</a></li>
                    <li><a href="#devtools" class="nav-link">DevTools</a></li>
                </ul>
            </div>
        </nav>

        <main class="main-content">
            <!-- STLC -->
            <section id="stlc" class="content-section">
                <h2 class="section-title">STLC (Software Testing Life Cycle)</h2>
                <div class="content-card">
                    <p class="content-text">STLC (Software Testing Life Cycle) - жизненный цикл тестирования — это структурированный процесс тестирования ПО, который полностью синхронизирован с этапами разработки (SDLC) - жизненный цикл ПО. Его главная цель — обеспечить высокое качество продукта через системный подход. Ключевые этапы STLC (классическая модель):</p><br>
                    <P class="content-text">1. Анализ требований (Requirement Analysis)
                    Цель: Понимание что тестировать.
                    Действия:
                     Изучение документации (ТЗ, пользовательские истории).
                     Выявление тестируемых и нетестируемых требований.
                     Определение критериев приёмки.
                     Результат: Чек-лист требований для тестирования.</P><br>
                    <P class="content-text">2. Планирование тестирования (Test Planning)
                     Цель: Определить как, когда и кем будет проводиться тестирование.
                     Действия:
                     Выбор методологий (ручное/автоматизированное тестирование).
                     Оценка трудозатрат, сроков, ресурсов.
                     Определение метрик (например, покрытие кода).
                     Создание Test Plan — главного документа этапа.
                     Результат: Тест-план, утверждённый командой.</P><br>
                    <P class="content-text"> 3. Проектирование тестов (Test Design)
                     Цель: Создать эффективные тест-кейсы.
                     Действия:
                     Разработка тест-кейсов, чек-листов.
                     Применение техник: классы эквивалентности, граничные значения, сценарии использования.
                     Подготовка тестовых данных и окружения.
                     Результат: Набор тест-кейсов, готовых к выполнению.</P><br>
                    <P class="content-text">4. Настройка среды (Test Environment Setup)
                     Цель: Создать условия для запуска тестов.
                     Действия:
                     Развёртывание тестового стенда (серверы, БД, сети).
                     Настройка оборудования/ПО (браузеры, ОС, мобильные устройства).
                     Проверка готовности среды (smoke-тесты).
                     Результат: Готовая к работе тестовая среда.</P><br>
                    <P class="content-text"> 5. Выполнение тестирования (Test Execution)
                     Цель: Выявить дефекты в продукте.
                     Действия:
                     Запуск тест-кейсов по плану (регресс, новые функции).
                     Фиксация результатов (успех/провал).
                     Логирование багов в трекер (Jira, Trello).
                     Ре-тест исправленных дефектов.
                     Результат: Отчёты о тестировании, баг-репорты.</P><br>
                    <P class="content-text"> 6. Завершение цикла (Test Closure)
                     Цель: Подвести итоги и извлечь уроки.
                     Действия:
                     Анализ метрик (количество найденных/исправленных багов, покрытие).
                     Оценка соответствия критериям завершения тестирования.
                     Подготовка итогового отчёта.
                     Ретроспектива: что улучшить в следующем цикле.
                     Результат: Test Closure Report, рекомендации.</P><br>
                    <P class="content-text"> Важно!
                     STLC ≠ SDLC (Software Development Life Cycle). Тестирование — часть SDLC, но имеет свою чёткую структуру.
                     Гибкость: В Agile/Scrum этапы STLC могут выполняться итерационно (например, тест-дизайн параллельно с разработкой).
                     Риск-ориентированность: На этапах 1-3 фокус смещается на самые критические области продукта.</P><br>
                    
                </div>
            </section>

            <!-- 7 Principles -->
            <section id="principles" class="content-section">
                <h2 class="section-title">7 Принципов тестирования</h2>
                <div class="content-card">
                     <P class="content-text">1. Тестирование показывает наличие дефектов, но не их отсутствие
                      (Testing shows presence of defects) → Простыми словами: Мы можем найти баги, но никогда не докажем, что программа идеальна. → Пример: Даже если проверили приложение 100 раз, нет гарантии, что на 101-й не вылезет ошибка.</P><br>
                      <P class="content-text">2. Невозможно «полное» тестирование
                       (Exhaustive testing is impossible) → Простыми словами: Проверить все комбинации данных, сценариев и устройств — нереально. → Что делать? Тестируем по приоритетам (что важнее для пользователя) и рискам (где вероятнее сломается).
                        </P><br>
                      <P class="content-text">3. Раннее тестирование экономит время и деньги
                       (Early testing saves time and money) → Простыми словами: Искать баги нужно как можно раньше — на этапе требований или дизайна. → Пример: Найти ошибку в ТЗ дешевле, чем переделывать готовый код.</P><br>
                      <P class="content-text">4. Дефекты группируются вместе
                       (Defects cluster together) → Простыми словами: Баги любят «кучки»! Где нашли одну ошибку — ищите рядом ещё. → Правило 80/20: 80% дефектов обычно сидят в 20% модулей (например, в сложном расчёте оплаты).</P><br>
                      <P class="content-text">5. Парадокс пестицида
                       (Pesticide paradox) → Простыми словами: Если постоянно использовать одни и те же тесты — баги к ним «привыкают». → Что делать? Регулярно обновляйте тест-кейсы и добавляйте новые сценарии!</P><br>
                      <P class="content-text">6. Тестирование зависит от контекста
                       (Testing is context dependent) → Простыми словами: Нет универсальных правил! Тестируем по-разному в зависимости от проекта. → Пример: Мобильная игра ≠ банковское приложение. Где-то важна безопасность, где-то — анимация.</P><br>
                      <P class="content-text">7. Заблуждение об отсутствии ошибок
                       (Absence-of-errors fallacy) → Простыми словами: Даже если программа технически безупречна — она бесполезна, если не решает задачи пользователя. → Пример: Идеальный калькулятор, который считает не то, что нужно людям.</P><br> 
                      <P class="content-text">Главная мысль:
                       Тестирование — это не про перфекционизм, а про разумный баланс. 
                       Мы ищем критические баги там, где они вероятнее всего есть, экономя ресурсы и фокусируясь на ценности для пользователя.</P><br> 
                </div>
            </section>

            <!-- Requirements -->
            <section id="requirements" class="content-section">
                <h2 class="section-title">Что такое требования?</h2>
                <div class="content-card">
                    <p class="content-text">В контексте разработки ПО (и IT-систем в целом) требования — это детальное описание того, что должна делать система, как она должна себя вести, и какие характеристики должна иметь. Это "инструкция" для разработчиков, тестировщиков и всех участников проекта, создаваемая обычно бизнес-аналитиком. Их главная цель — четко и однозначно зафиксировать ожидания заказчика и функционал системы до начала дорогостоящей разработки.</p><br>
                          <p class="content-text">Шесть ключевых атрибутов:</p> 
                          <p class="content-text">1.Полнота (Completeness):
                         Что это: В требованиях должно быть описано ВСЕ необходимое для реализации и тестирования функционала. Ничего не должно быть упущено: основной сценарий, альтернативные потоки, обработка ошибок, все параметры, все условия.
                         Как проверить: Написать подробный чек-лист тестов сразу при чтении ТЗ. Если при составлении чек-листа возникают вопросы типа "А что если...?" или обнаруживаются "белые пятна" — требование неполное.
                         Пример из статьи: Аналитик не описал все возможные сценарии поведения нового поля. Тестировщик, прикидывая тесты "в уме", тоже их упустил. Пробелы вскрылись только при детальном написании автотестов после согласования ТЗ, что привело к дополнительным затратам.</p><br> 
                          <p class="content-text">2.Однозначность (Unambiguity):
                         Что это: Требование должно иметь ТОЛЬКО ОДНО возможное толкование. Все участники проекта (заказчик, аналитик, разработчик, тестировщик) должны понимать его одинаково.
                         Как проверить: Искать любые субъективные формулировки, относительные понятия, местоимения без четкой привязки. Все должно быть конкретно.
                         Пример: "Отчет должен загружаться быстро" — неоднозначно. Для кого быстро? Решение: "Отчет за год должен загружаться ≤1 сек, отчет за весь период ≤5 сек". Не указанное значение по умолчанию для поля (0 или пустота?) тоже ведет к разному пониманию.</p><br> 
                          <p class="content-text">3.Непротиворечивость (Consistency):
                         Что это: Требования НЕ ДОЛЖНЫ ПРОТИВОРЕЧИТЬ друг другу или другим частям документации (например, нефункциональным требованиям).
                         Как проверить: Сравнивать требования между собой и с другими документами (особенно при большом объеме). Искать прямые конфликты в описаниях поведения или характеристик.
                         Пример: В общих НФТ указано: "Любая страница ≤3 сек". В ТЗ конкретного отчета: "Может грузиться до 1 минуты". Явное противоречие.</p><br> 
                          <p class="content-text">4.Необходимость (Necessity / Conciseness):
                         Что это: Требования должны содержать ТОЛЬКО СУЩЕСТВЕННУЮ информацию. Избегайте избыточности, описания очевидных вещей или того, что не относится к данному функционалу.
                         Как проверить: Задавать вопрос: "А действительно ли это нужно описать здесь? Поможет ли это разработчику/тестировщику/пользователю?".
                         Пример из статьи: Не нужно подробно описывать каждую кнопку интерфейса, если их поведение стандартно и очевидно. В ТЗ фокусироваться на функционале, сценариях, ошибках; в пользовательской документации — на использовании, а не на базовых операциях.</p><br> 
                          <p class="content-text">5.Осуществимость (Feasibility / Realisability):
                         Что это: Требование должно быть ТЕХНИЧЕСКИ ВЫПОЛНИМО в рамках бюджета, сроков, технологий и архитектуры системы.
                         Как проверить: Обычно это проверяют разработчики, оценивая сложность реализации. Требование не должно быть фантастическим ("загрузка миллиона данных за 0.1 сек") или требовать непропорционально больших затрат для малой пользы.
                         Пример: Желание сделать "идеально точный" поиск по нескольким параметрам одного атрибута (домашний адрес + улица Ленина) может потребовать огромных серверных ресурсов и быть экономически нецелесообразным, если выгода от отсеивания нескольких лишних записей невелика. Требуется баланс и компромисс.</p><br> 
                          <p class="content-text">6.Тестируемость (Testability):
                         Что это: Функционал, описанный в требовании, ДОЛЖЕН БЫТЬ ВОЗМОЖЕН ДЛЯ ПРОВЕРКИ (как вручную, так и автоматически, если это предполагается).
                         Как проверить: Представить, как именно вы будете тестировать это требование. Можно ли создать тестовые данные? Можно ли наблюдать результат? Можно ли автоматизировать проверку? Если нет — требование нужно доработать.
		                 Пример: Рефакторинг кода (изменение структуры без изменения функционала) сложно полноценно проверить тестировщику без помощи разработчика. Неучет необходимости доработки фреймворка автотестов под новый функционал (отправка в две JMS-очереди вместо одной) приводит к задержкам в тестировании.</p><br> 
                          <p class="content-text">Итог:
                         Хорошие требования — это полное, однозначное, непротиворечивое, необходимое, осуществимое и тестируемое описание функционала системы. Проверка требований (их "тестирование") на соответствие этим атрибутам до начала разработки — критически важный этап, который экономит огромное количество времени, денег и нервов на последующих стадиях проекта.</p><br>      
                </div>
            </section>

            <!-- Metrics -->
            <section id="metrics" class="content-section">
                <h2 class="section-title">Метрики тестирования</h2>
                <div class="content-card">
                    <p class="content-text">Метрики тестирования 
                     — это "цифровой пульс" проекта. Они помогают понять эффективность тестирования, качество продукта и принять взвешенные решения.</p><br>
                    <p class="content-text">Классификация метрик (для структуры):
                     1. Метрики процесса тестирования (как мы работаем).
                     2. Метрики качества продукта (что мы выпускаем).
                     3. Метрики эффективности исправлений (как команда реагирует на баги).</p><br>
                    <p class="content-text">1. Метрики процесса тестирования
                     <p>➔ Test Coverage (Покрытие тестами)</p>
                     <p>Что измеряет: % функционала/кода/требований, охваченных тест-кейсами. Формула: (Количество покрытых сущностей / Общее количество сущностей) * 100% Пример:</p>
                     <p>Требований: 50 → Покрыто тестами: 45 → Покрытие = 90% Важно: Не гнаться за 100%! Риск "пустого" покрытия без глубины.</p>

                     <p>➔ Test Execution Progress (Прогресс выполнения тестов)</p>
                     <p>Что измеряет: Скорость прохождения тест-кейсов. Формула: (Выполненные тесты / Всего запланированных) * 100% Пример: Инсайт: Резкое замедление → пора бить тревогу (среда, сложность багов).</p>

                     <p>➔ Test Case Effectiveness (Эффективность тест-кейсов)</p>
                     <p>Что измеряет: Сколько тестов нашли реальные баги. Формула: (Количество тест-кейсов, выявивших баги / Всего выполненных тест-кейсов) * 100% Золотое правило: Хороший показатель — 15-30%. Ниже → тесты поверхностные, выше → много дублей.</p>
                      </p><br>
                    <p class="content-text"> 2. Метрики качества продукта</p>
                      <p>➔ Defect Density (Плотность дефектов)</p>
                     <p>Что измеряет: Количество багов на единицу размера продукта (модуль, экран, 1000 строк кода). Формула: Общее количество багов / Размер модуля Пример:</p>
                     <p>Модуль "Оплата": 15 багов / 5 экранов → Плотность = 3 бага/экран. Как использовать: Выявить "горячие" модули для углублённого тестирования.</p>

                    <p> ➔ Defect Severity Index (Индекс серьёзности дефектов)</p>
                     <p>Что измеряет: Взвешенную оценку критичности багов. Формула:</p>
                     

                          <p>(Кол-во Critical * 3) + (Major * 2) + (Minor * 1) + (Trivial * 0.5)</p>  
                      <p> ─────────────────────────────────────────────────</p>
                          <p> Общее количество багов</p>
                       <p>Пример:</p>
                      <p>Critical: 2, Major: 5, Minor: 10 → Индекс = (2*3 + 5*2 + 10*1) / 17 = 26/17 ≈ 1.53 Интерпретация:</p>
                       <p>2.0: Катастрофа! </p>
                       <p>1.0–1.9: Высокий риск.</p>
                       <p>< 1.0: Приемлемо.</p>

                       <p>➔ Defect Leakage (Утечка дефектов)</p>
                       <p>Что измеряет: Баги, пропущенные QA и найденные после релиза. Формула: (Баги в продакшене / Всего найденных багов) * 100% Критичный порог: > 5% — тревога!</p><br>
                    <p class="content-text">3. Метрики эффективности исправлений
                       <p>➔ Defect Rejection Rate (% отклонённых багов)</p>
                       <p>Что измеряет: Долю багов, отклонённых разработчиками (как "Not a Bug"). Формула: (Отклонённые баги / Всего заведённых) * 100% Норма: < 10%. Выше → проблемы с:</p>
                       <p>Качеством баг-репортов,</p>
                       <p>Пониманием требований,</p>
                       <p>Коммуникацией в команде.</p>
                       <p>➔ Defect Aging (Возраст дефекта)</p>
                       <p> Что измеряет: Время от создания бага до его исправления. Пример:</p>
                       <p>  Серьёзность	Допустимый срок</p>
                       <p> Critical	≤ 24 часов</p>
                       <p> Major	≤ 3 дней</p>
                       <p> Minor	≤ 1 спринта</p>
                        <p>Инсайт: Старые баги = риск забытых дефектов.</p><br>
                    <p class="content-text">Опасные метрики (не используйте без контекста!):
                       <p>Общее количество багов: 100 багов ≠ плохое качество! Может означать тщательное тестирование.</p>
                       <p>Скорость закрытия багов: Быстро ≠ хорошо. Важно качество фикса.</p>
                       <p>Количество тест-кейсов: 500 тестов ≠ хорошее покрытие. Возможен "мусорный" объём.</p><br>
                    <p class="content-text">Как применять метрики на практике:
                       <p>1. Собирайте данные автоматически (Jira, TestRail, qTest).</p>
                       <p>2. Анализируйте тренды, а не разовые цифры.</p>
                       <p>3. Задавайте вопросы:</p>
                       <p>Почему вырос - утечка дефекта (Defect Leakage)? → Слабое тестирование новых сценариев?</p>
                       <p>Почему низкий Эффективность тестовых случаев (Test Case Effectiveness)? → Тесты устарели?</p>
                      <p>4. Действуйте на основе инсайтов:</p>
                        <p>Увеличьте покрытие рискованных модулей,</p>
                        <p>Пересмотрите критерии серьёзности багов,</p>
                       <p>Проведите воркшоп по написанию баг-репортов.</p><br>
                     <p class="content-text">Золотое правило:Метрики должны приводить к действиям, а не к отчётам ради отчётов.</p>
                     <p class="content-text">Пример: Как метрики спасли проект
                     <p>Ситуация:</p>
                     <p>Плотность дефектов в модуле "Отчётность": 8 багов/экран (при норме ≤ 2).</p>
                     <p>Индекс серьёзности: 2.1 (Critical/Major баги). Действия:</p>
                     <p>1. Остановили разработку новых фич.</p>
                     <p>2. Собрали целевую группу (task-force) для рефакторинга модуля.</p>
                     <p>3. Увеличили покрытие модуля с 70% до 95%. Результат:</p>
                     <p>После рефакторинга: плотность дефектов = 0.5/экран.</p>
		             <p>Утечка дефектов снизилась с 7% до 1%.</p><br>
                </div>
                
                <h3 class="subsection-title">Метрики тестирования (второй раздел)</h3>
                <div class="content-card">
                    <p class="content-text">Метрики тестирования 
                      — это не просто цифры для отчётов, а мощный инструмент для управления качеством. Вот ключевые цели, ради которых их используют (разберём как на ладони):</p>
                    <p class="content-text">1. Принимать объективные решения
                     <p>Зачем? Без метрик решения строятся на интуиции («Кажется, багов много, надо переносить релиз»). Примеры:</p>
                     <p>Плотность дефекта (Defect Density) > 5 багов/модуль?* → Решение: Усилить тестирование этого модуля.</p>
                     <p>Утечка дефектов (Defect Leakage) > 7%? → Решение: Пересмотреть тест-кейсы для регресса.</p>
                     <p>Тестовое Покрытие (Test Coverage) < 70%? → Решение: Запланировать создание новых тестов.</p>
                     <p>Итог: Метрики превращают мнения в факты.</p><br>
                     <p class="content-text">2. Контролировать процесс тестирования
                     <p>Зачем? Чтобы понять:</p>
                     <p>Успеваем ли мы по графику? Ход выполнения теста (Test Execution Progress),</p>
                     <p>Эффективны ли наши тесты? Эффективность Тестовых Случаев (Test Case Effectiveness),</p>
                     <p>Не «тонем» ли в багах? Дефект Старения (Defect Aging).</p>
                     <p>Пример Agile-спринта:</p>
                     <p>Метрика 	План	Факт	Действие</p>
                     <p>Покрытие тестами	85%	78%	Добавить 10 тест-кейсов</p>
                      <p>Утечка дефектов	≤ 3%	0% ✅	Фокус на новых фичах</p>
                     <p>% отклонённых багов	≤ 10%	15% 🚨	Тренинг по баг-репортам</p>
                         Итог: Метрики — это «приборная панель» QA-команды.</p><br>
                    <p class="content-text">3. Оценивать качество продукта
                     <p>Зачем? Чтобы ответить бизнесу: «Можно ли выпускать продукт?». Ключевые метрики качества:</p>
                     <p>Индекс Тяжести Дефекта(Defect Severity Index): Если > 2.0 — продукт сырой.</p>
                     <p>Распределение дефектов (Defect Distribution): 80% багов в одном модуле? Риск для стабильности!</p>
                     <p>Процент Сдачи Теста (Test Pass Rate): % успешных тестов. Если < 90% — критично.</p>
                     <p>Пример релиза:</p>
                       <p>markdown</p>

                      <p>✅ DSI = 1.2 (приемлемо)</p>  
                       <p>✅ Pass Rate = 92% </p> 
                      <p>⚠️ Плотность багов в "Оплате" = 4.1 (но ниже, чем в прошлом релизе 6.3 → тенденция положительная!) </p> 
                       Решение: Выпускаем с пометкой «Мониторить оплату».</p><br>
                    <p class="content-text">4. Находить слабые места в процессе
                      <p>Зачем? Улучшать не только продукт, но и как мы работаем. Примеры проблем по метрикам:</p>
                      <p>Высокий  Скорость Отказа От Дефекта (Defect Rejection Rate) (20%) → Плохие баг-репорты? Непонятные требования?</p>
                      <p>Низкий Эффективность Тестовых Случаев(Test Case Effectiveness) (8%) → Тесты не релевантны? Пишем «в стол»?</p>
                      <p>Долгий Дефект старения для незначительных(Defect Aging для Minor)-багов (30 дней)* → Разработчики игнорируют мелкие дефекты?</p>
                      <p>Итог: Метрики — диагност для процессов команды.</p><br>
                    <p class="content-text">5. Оптимизировать ресурсы и бюджет
                     <p>Зачем? Тестирование стоит денег. Метрики показывают, где мы теряем эффективность. Пример:</p>
                     <p>На регресс-тестах тратится 40% времени, но эффективность тестов всего 10%* → Действие: Автоматизировать рутину, пересмотреть сценарии.</p>
                     <p>Утечка дефекта (Defect Leakage) в 10% приводит к 200 часам доп. работы после релиза → Действие: Увеличить тестирование на 15%, что сэкономит 180 часов.</p>
                      <p>Итог: Метрики помогают тратить время/деньги там, где это даст максимум пользы.</p><br>
                    <p class="content-text"> Чего НЕЛЬЗЯ делать с метриками (опасность!):
                       <p>Гнаться за «красивыми» цифрами: 100% покрытие ≠ 100% качество.</p>
                       <p>Наказывать команду за метрики: «Из-за утечки багов лишаем премии!» → люди начнут скрывать ошибки.</p>
                     <p>Использовать их изолированно: Без контекста метрики лгут (например, 50 Critical-багов — это хорошо, если в прошлом релизе их было 200).</p><br>
                    <p class="content-text">Главный принцип:
                     <p>Метрики должны вести к действиям, а не к отчётам. Хорошая практика:</p>
                      <p>1. Собирать данные (Jira, TestRail).</p>
                      <p>2. Раз в спринт/месяц анализировать тренды.</p>
                       <p>3. Ставить SMART-цели на основе метрик:  «Снизить Defect Leakage с 7% до 4% за 2 спринта через:</p>
                       <p>Пересмотр 50 регресс-тестов,</p>
                       <p> Введение exploratory testing,</p>
                       <p>Еженедельный баг-трейнинг»*.</p><br>
                    <p class="content-text">Пример из практики:
                       <p>Проблема: После релиза пользователи массово жаловались на падение приложения. Анализ метрик:</p>
                       <p>Утечка (Defect Leakage) = 12% (при норме ≤5%),</p>
                       <p>Тестовое покрытия (Test Coverage) модуля «Профиль» = 60% (самый низкий показатель),</p>
                       <p>Тяжесть дефекта (Defect Severity) Index в этом модуле = 0.8 (мелкие баги → команда его проигнорировала). Решение:</p>
                       <p>Ввели обязательное 90% покрытие для ключевых модулей,</p>
                       <p>Добавили нагрузочное тестирование для «Профиля»,</p>
                         Через 2 месяца Утечка (Defect Leakage) упал до 3%.</p><br>
                </div>
            </section>

            <!-- Testing Types -->
            <section id="testing-types" class="content-section">
            <h2 class="section-title">ВИДЫ ТЕСТИРОВАНИЯ</h2>
                  <div class="content-card">
                    <p class="content-text">Все виды тестирования можно разделить на 2 вида: это функциональное и нефункциональное тестирование.
                      Почему именно так?</p><br>
                      <p class="content-text">1. Функциональное тестирование (functional testing) рассматривает заранее указанное поведение и основывается на анализе спецификации компонента или системы в целом, т.е. проверяется корректность работы функциональности приложения.
                      <p>2. Нефункциональное тестирование (non-functional testing) — тестирование атрибутов компонента или системы, не относящихся к функциональности.</p><br>
                       <p class="content-text">Простое объяснение (как мы любим):
                      <p>Функциональное тестирование: Отвечает на вопрос "ЧТО система ДЕЛАЕТ?".</p>
                     <p> Примеры из жизни: Работает ли кнопка "Купить"? Сохраняется ли введенный текст? Правильно ли считается сумма заказа? Отправляется ли письмо после регистрации?</p>
                      <p>Это проверка конкретных функций: оплата, поиск, регистрация, добавление в корзину и т.д.</p>
                      <p>Нефункциональное тестирование: Отвечает на вопрос "КАК система это ДЕЛАЕТ?" (насколько хорошо, безопасно, удобно и т.д.).</p>
                      <p>Примеры из жизни: Насколько быстро загружается страница? Выдержит ли сайт 1000 пользователей одновременно? Удобно ли расположены кнопки? Не украдут ли хакеры мои данные? Работает ли приложение на старом телефоне?</p>
                    Это проверка характеристик: скорость (производительность), устойчивость к нагрузке (нагрузочное), удобство (usability), безопасность (security), совместимость с разными устройствами/браузерами (compatibility), надежность и т.д.</p><br>
                     <p class="content-text">Важно помнить:
                  <p>Это классификация по целям тестирования. Это самый фундаментальный способ разделить огромный мир тестирования на две большие группы.</p>
                     Внутри каждой из этих двух групп есть множество других видов тестирования (которые тоже перечислены в статье: модульное, интеграционное, системное, регрессионное, приемочное, usability, security, performance и т.д.). Но все они логично вписываются либо в "что делает?" (функциональные), либо в "как делает?" (нефункциональные).</p><br>
                     <p class="content-text">Другие квалификации по знанию системы, по уровню, по исполнителям и т.д. например:
                     <p>По знанию системы: Черный ящик, Белый ящик, Серый ящик.</p>
                     <p>По уровню: Модульное (Unit), Интеграционное (Integration), Системное (System).</p>
                     <p>По исполнителям: Альфа-тестирование, Бета-тестирование.</p>
                     <p>По хронологии: Повторное (Re-testing), Регрессионное (Regression).</p>
                      <p>Однако есть 2 главных вида </p>
                      <p>ФУНКЦИОНАЛЬНОЕ и НЕФУНКЦИОНАЛЬНОЕ.</p><br>
                </div>

                <h3 class="subsection-title">Функциональное тестирование</h3>
                <div class="content-card">
                    <p class="content-text">— это проверка того, что делает система, соответствует ли её поведение ожидаемому согласно спецификациям, требованиям и пользовательским ожиданиям. Другими словами, это тестирование функций или возможностей программного обеспечения.
                      Проще говоря: Это ответ на вопрос: "Работает ли эта штука так, как задумано?"</p><br>
                     <p class="content-text">🔑 Ключевые характеристики функционального тестирования (из статьи и практики):
                       1.Основано на требованиях и спецификациях: → Тестировщик проверяет, соответствует ли поведение программы документации (ТЗ, user stories, спецификациям). Пример: Если в требованиях сказано: "При нажатии кнопки 'Сохранить' данные должны записываться в базу", то именно это и проверяется.</p><br>
                     <p class="content-text">2 .Проверяет бизнес-логику и пользовательские сценарии: → Фокус на том, решает ли ПО поставленную бизнес-задачу. Пример:
                     <p>Может ли пользователь зарегистрироваться?</p>
                     <p>Правильно ли рассчитывается скидка в корзине?</p>
                     <p>Отправляется ли письмо после оформления заказа</p><br>
                    <p class="content-text">3.Отвечает на вопрос "ЧТО?": → Что делает система? Какие функции она предоставляет? (В отличие от нефункционального, которое отвечает на "КАК?" — как быстро, надежно, удобно и т.д.)</p><br>
                    <p class="content-text">4.Использует техники тест-дизайна:  Эквивалентное Разделение, Анализ Граничных Значений, Таблицы Решений, Сценарии Использования (Use Cases), Причина/Следствие. Пример (Boundary Values): Проверка поля "Возраст": ввод 17, 18, 19 лет (границы 18+).</p><br>
                    <p class="content-text">5.Может проводиться на любом уровне: → Модульное (Unit), Интеграционное (Integration), Системное (System), Приёмочное (Acceptance) тестирование — все они включают функциональные проверки. Пример на разных уровнях:
                    <p>Модульное (unit): Проверяет, что функция Рассчитать скидку возвращает правильную скидку для суммы 1000 руб.</p>
                      Системное System: Проверяет, что весь процесс "Добавить товар в корзину → Оформить заказ → Оплатить" работает корректно.</p><br>
                    <p class="content-text">6.Основные виды проверок: → Позитивные: Корректные данные → Ожидаемый результат (например, верный логин/пароль → вход в систему). → Негативные: Некорректные данные → Обработка ошибок (например, неверный пароль → сообщение об ошибке). → Экстремальные: Проверка на "крайних" значениях и условиях.</p><br>
                    <p class="content-text">🎯 Цель функционального тестирования:
                     Найти расхождения между реальным поведением системы и ожидаемым (описанным в требованиях). Убедиться, что продукт решает задачи пользователя правильно.</p><br>
                    <p class="content-text">🔍 Как это выглядит на практике? Пример из жизни:
                      <p>Система: Интернет-магазин. Требование: "Пользователь может добавить товар в корзину".</p>
                      <p>Функциональные тесты проверят:</p>
                      <p>1. Можно ли нажать кнопку "Добавить в корзину"?</p>
                     <p>2. Появляется ли товар в корзине после нажатия?</p>
                     <p>3. Правильно ли отображается название, цена, количество?</p>
                     <p>4. Сохраняется ли товар в корзине после перезагрузки страницы?</p>
                      <p>5. Что происходит, если добавить один товар дважды?</p>
                      <p>6. Можно ли добавить 999 товаров (граничное значение)?</p>
                     <p>7. Выдается ли ошибка, если попытаться добавить недоступный товар?</p><br>
                    <p class="content-text">⚠️ Чем функциональное тестирование НЕ является?
                      <p>Не проверяет производительность: Сколько времени загружается корзина? (это нагрузочное тестирование → нефункциональное).</p>
                     <p>Не проверяет безопасность: Можно ли взломать корзину? (это тестирование безопасности → нефункциональное).</p>
                     <p>Не проверяет удобство: Удобно ли расположена кнопка? (это Удобность использования usability-тестирование → нефункциональное).</p><br>
                    <p class="content-text">📊 Главный инструмент функционального тестирования — Тест-кейсы (Test Cases):
                      <p>Они строятся на основе требований и содержат четкие шаги:</p>
                     <p>1. Предусловия (например, пользователь авторизован).</p>
                     <p>2. Шаги воспроизведения (например: "Открыть карточку товара → Нажать 'Добавить в корзину'").</p>
                     <p>3. Ожидаемый результат (например: "Товар появился в корзине, счетчик корзины увеличился на 1").</p><br>
                    <p class="content-text">Итог: Функциональное тестирование — это "список покупок" для QA. Мы берем требования (список того, что нужно купить → что система должна делать), идем в магазин (тестируемое приложение) и проверяем, всё ли купили (всё ли работает, как написано). 🛒✅</p><br>
                </div>

                <h3 class="subsection-title">Нефункциональное тестирование</h3>
                <div class="content-card">
                    <p class="content-text">Нефункциональное тестирование — это тестирование атрибутов компонента или системы, не относящихся к функциональности.</p>
                     <p class="content-text">Нефункциональное тестирование:
                    Отвечает на вопрос "КАК система это делает?". Оценивает качество работы системы, ее характеристики, а не саму функциональность. Это про удобство, скорость, надежность, защищенность.</p><br>
                    <p class="content-text">5 примеров нефункционального тестирования:
                    <p>1.Тестирование Производительности (Performance Testing):</p>
                     <p>Что проверяем: Насколько быстро система работает? Как быстро загружается страница? Как быстро выполняется запрос к базе данных? Как быстро обрабатывается платеж?</p>
                       Пример из жизни: Тестировщик замеряет время открытия главной страницы сайта при 1000 одновременных пользователей. Цель: убедиться, что страница грузится не дольше 3 секунд. Это не про то, открылась ли страница вообще (функциональность), а про то, насколько БЫСТРО она открылась (качество).</p><br>
                    <p class="content-text">2.Нагрузочное тестирование (Load Testing):
                    <p>Что проверяем: Как система ведет себя под нагрузкой? Выдержит ли она наплыв пользователей? Не "упадет" ли? Не начнет ли дико тормозить?</p>
                      Пример из жизни: Перед стартом распродажи тестировщики имитируют вход на сайт 10 000 пользователей одновременно, которые начинают добавлять товары в корзину. Смотрят: не зависает ли сайт, не появляются ли ошибки "Сервер недоступен", не падает ли производительность до неприемлемого уровня. Проверяется не функция "добавления в корзину" (она уже работает), а то, как система СПРАВЛЯЕТСЯ с МНОЖЕСТВОМ таких запросов сразу.</p><br>
                    <p class="content-text">3.Тестирование Удобства Использования (Usability Testing):</p>
                     <p>Что проверяем: Насколько система удобна и понятна для пользователя? Легко ли найти нужную кнопку? Интуитивен ли интерфейс? Не нужно ли совершать лишних действий?</p>
                      Пример из жизни: Тестировщик (или реальный пользователь) пытается оформить заказ на сайте. Смотрят: понятна ли последовательность шагов? Легко ли найти корзину? Ясно ли написаны подписи к полям? Не приходится ли слишком много скроллить или кликать? Проверяется не то, оформляется ли заказ вообще (функция), а то, насколько ЭФФЕКТИВНО, БЫСТРО и БЕЗ ЗАТРУДНЕНИЙ это может сделать пользователь.</p><br>
                    <p class="content-text">4.Тестирование Безопасности (Security Testing):
                     <p>Что проверяем: Насколько хорошо система защищена от злоумышленников? Нельзя ли украсть данные? Нельзя ли взломать аккаунт? Нельзя ли вывести систему из строя?</p>
                      <p>Пример из жизни: Тестировщик пытается:</p>
                      <p>Ввести SQL-код в поле ввода логина (SQL-инъекция).</p>
                     <p>Подобрать пароль методом грубой силы.</p>
                     <p>Передать вредоносный файл через форму загрузки.</p>
                      Получить доступ к данным без авторизации. Смотрят, блокирует ли система такие попытки, защищает ли данные. Проверяется не функция ввода логина/пароля, а то, насколько НАДЕЖНО система защищена от злоупотребления этой функцией.</p><br>
                    <p class="content-text">5.Тестирование Совместимости (Compatibility Testing):
                     <p>Что проверяем: Корректно ли система работает в разных окружениях? На разных браузерах (Chrome, Firefox, Safari)? На разных операционных системах (Windows, macOS, Linux, Android, iOS)? На разных устройствах (ПК, ноутбук, планшет, телефон)? С разным разрешением экрана?</p>
                     <p>Пример из жизни: Тестировщик открывает один и тот же интернет-магазин на:</p>
                       <p>Windows 10 в Chrome, Firefox, Edge.</p>
                       <p>macOS в Safari и Chrome.</p>
                      <p> iPhone (iOS) в Safari.</p>
                     Android-смартфоне в Chrome. Смотрит: не "плывет" ли верстка? Все ли кнопки нажимаются? Корректно ли отображаются изображения и текст? Проверяется не сами функции сайта (они работают на основном браузере), а то, как они ВЫГЛЯДЯТ и РАБОТАЮТ в РАЗНЫХ УСЛОВИЯХ.</p><br>
                    <p class="content-text">Ключевая мысль для запоминания:
                     <p>Представь, что тестируешь машину.</p>
                     <p>Функциональное: Заводится ли двигатель? Работают ли фары? Переключаются ли передачи? Едет ли вперед/назад?</p>
                      <p>Нефункциональное:</p>
                     <p>Производительность: Как быстро разгоняется до 100 км/ч?</p>
                     <p>Нагрузка: Как ведет себя при полной загрузке багажника и 5 пассажирах в гору?</p>
                     <p>Удобство: Удобно ли расположены педали и руль? Хорошо ли читается приборная панель?</p>
                     <p> Безопасность: Насколько надежны подушки безопасности и система ABS?</p>
		        Совместимость: Едет ли она по асфальту, грунтовке, в дождь? (Это больше аналог проверки в разных условиях, как совместимость ПО).</p><br>
                </div>

                <h3 class="subsection-title">Тестирование «ящиков»</h3>
                <div class="content-card">
                    <p class="content-text"> — это классификация методов тестирования ПО по уровню доступа тестировщика к внутренней структуре системы (коду). Давай разберем максимально просто, с примерами и аналогиями:</p>
                         <p class="content-text">1. Тестирование Чёрного Ящика (Black Box Testing)
                         <p> Доступ к коду: Нет доступа. Тестировщик видит только «внешность» системы — как обычный пользователь. Что проверяет: Поведение системы на соответствие требованиям (спецификации). Аналогия: Как проверять машину, не зная её устройства. Садишься за руль, жмешь газ — смотришь, едет ли. Примеры тестов:</p>
                         <p>Корректность входа в приложение по логину/паролю.</p>
                             <p> Добавление товара в корзину в интернет-магазине.</p>
                              Проверка, что кнопка «Отправить» вызывает отправку формы. Методы: Эквивалентное разделение, анализ граничных значений, тест-кейсы на основе сценариев использования. Кто тестирует: QA-инженеры, бизнес-аналитики. Плюсы: Тестирует систему «глазами пользователя», не требует знаний программирования. Минусы: Не проверяет внутреннюю логику; могут остаться незамеченными ошибки в коде.</p><br>
                    <p class="content-text">2. Тестирование Белого Ящика (White Box Testing)
                        <p> Доступ к коду: Полный доступ. Тестировщик знает всю внутреннюю структуру, алгоритмы, код. Что проверяет: Качество кода, логику работы, пути выполнения, обработку ошибок. Аналогия: Как механик, который разбирает двигатель и проверяет каждую деталь. Примеры тестов:</p>
                        <p>Проверка всех ветвей if-else в коде.</p>
                        <p>Тестирование циклов на граничных значениях (например, пустой массив).</p>
                        Анализ покрытия кода тестами (statement, branch coverage). Методы: Тестирование путей, условий, циклов; статический анализ кода. Кто тестирует: Разработчики (unit-тесты), реже — тестировщики с навыками программирования. Плюсы: Находит скрытые ошибки в логике, оптимизирует код. Минусы: Требует глубоких знаний кода; не проверяет соответствие требованиям «снаружи».</p><br>
                    <p class="content-text">3. Тестирование Серого Ящика (Gray Box Testing)
                     <p>Доступ к коду: Частичный доступ. Тестировщик знает архитектуру, базу данных, API, но не детали реализации. Что проверяет: Взаимодействие компонентов, интеграцию, поведение системы при частичном знании её устройства. Аналия: Как водитель, который знает, где бензобак и двигатель, но не лезет в цилиндры. Примеры тестов:</p>
                     <p> Проверка, как фронтенд отправляет данные в бэкенд через API.</p>
                     <p>Тестирование работы с базой данных (корректно ли сохраняются/читаются данные).</p>
                      Анализ логов системы при выполнении сценария. Методы: Таблицы решений, тестирование состояний, интеграционные тесты. Кто тестирует: QA-инженеры (чаще всего!), DevOps. Плюсы: Баланс между пользовательским и глубинным тестированием; эффективен для поиска интеграционных ошибок. Минусы: Требует понимания архитектуры, но не полного погружения в код.</p><br>
                    <p class="content-text">Ключевые различия в таблице:
                    </p>Критерий	Чёрный Ящик	Белый Ящик	Серый Ящик</p>
                    </p>Доступ к коду	Нет	Полный	Частичный</p>
                    </p>Объект тестов	Внешнее поведение	Код/логика	Поведение + интеграция</p>
                    </p>Кто выполняет	Тестировщик	Разработчик	Тестировщик/DevOps</p>
                     </p>Примеры	UI-тесты, сценарии	Юнит-тесты, ревью кода	API-тесты, тесты БД</p>
                     </p>💡 Почему это важно?</p>
                     </p>Чёрный ящик — основа для QA: проверяешь, что система делает то, что нужно.</p>
                    </p>Белый ящик — глубокая оптимизация кода (чаще на стороне dev).</p>
                    </p>Серый ящик — золотая середина в реальных проектах: ты знаешь достаточно, чтобы тестировать эффективно, но не тратишь время на чтение всего кода.</p>
                    🔥 На практике: Большинство QA-инженеров работают в сером ящике (тестируют API, логи, БД, интеграции), дополняя это чёрноящичными тестами интерфейса. Белый ящик — это чаще зона ответственности разработчиков.</p><br>
                </div>

                <h3 class="subsection-title">Smoke-тест</h3>
                <div class="content-card">
                    <p class="content-text">Smoke-тест (Дымовое тестирование) — это быстрая проверка ОСНОВНЫХ функций приложения после новой сборки (версии), чтобы убедиться, что оно "не сгорело" (как при первом включении нового устройства: пошел дым — явно что-то не так!).</p>
                     <p class="content-text">Представь себе строителей, которые только что возвели каркас дома. Прежде чем начинать отделку, они быстро проверят:
                       <p>1. Стоит ли дом? (не рухнул)</p>
                       <p>2. Есть ли стены и крыша? (базовые элементы на месте)</p>
                       <p>3. Не течет ли крыша? (критичные проблемы)</p>
                        Smoke-тест в IT — это ровно такая же "первичная проверка каркаса" программы.</p><br>
                    <p class="content-text">Ключевые характеристики Smoke-теста (Из статьи + пояснения):
                 <p>1. Цель: Проверить, стабильна ли новая сборка и готова ли она к более глубокому тестированию (регрессу, функциональному тестированию). "Не сломали ли мы совсем всё?"</p>
                 <p>2. Когда выполняется: Сразу после каждой новой сборки (выпуска новой версии программы для тестирования).</p>
                 <p>3. Что проверяет: Минимальный набор КРИТИЧНО ВАЖНЫХ функций (основные пользовательские сценарии). Фокус на том, что должно работать ВООБЩЕ.</p>
                 <p> Примеры из статьи: Вход в систему, Регистрация, Основное действие приложения (просмотр профиля), Редактирование основных данных, Работа ключевых интеграций (отправка писем, скачивание файлов, карты).</p>
                 <p>4. Глубина: Поверхностная. Проверяем, что функция запускается и выполняет свою основную задачу (например, кнопка "Войти" ведет в систему при верном пароле), а не все ее тонкости и граничные случаи.</p>
                 <p>5. Скорость: Быстро! Набор тестов должен выполняться за минуты или десятки минут.</p>
                 <p>6. Кто выполняет: Могут тестировщики или иногда разработчики перед передачей билда в тестирование.</p>
                 <p>7. Результат:</p>
                 <p> Pass (Пройден): Основные функции работают -> Можно запускать углубленное тестирование (регресс, функциональное).</p>
                  Fail (Не пройден): Хотя бы одна критичная функция сломана -> Сборка нестабильна. Тестирование останавливается, сборка возвращается разработчикам на срочное исправление. Запускать длительные тесты на такой сборке бессмысленно и дорого.</p><br>
                    <p class="content-text">🧠 Почему Smoke-тест ОЧЕНЬ важен? (Преимущества из статьи)
                    <p>Раннее обнаружение грубых ошибок: Находит "пожар" (критичные баги) сразу после "постройки" (сборки), а не после недели тестирования.</p>
                    <p> Экономия времени и ресурсов: Не тратится время команды тестирования на запуск сотен тестов на заведомо нерабочей сборке. Представь, что ты тестируешь корзину магазина, а потом выясняется, что вход в систему вообще не работает!</p>
                     <p>Повышение качества: Гарантирует, что на углубленное тестирование попадают только стабильные сборки.</p>
                     Простота: Набор тестов обычно небольшой и хорошо известен команде.</p><br>
                <p class="content-text">⚖️ Smoke vs Sanity vs Регрессионное тестирование (Ключевые отличия из статьи)
                       Представь, что программа — это автомобиль:
                       <p>Характеристика	Smoke-тест (Дымовой)	Sanity-тест (Санитарный / Здравомыслия)	Регрессионное тестирование (Регресс)</p>
                       <p> Аналогия	Заводится ли? Едут ли вперед? Горят ли фары?	После замены колеса: Только колесо крутится?	Полный техосмотр после любого ремонта.</p>
                       <p> Цель	Готова ли сборка к тестированию? ("Не сломано ли всё?")	Корректно ли реализовано КОНКРЕТНОЕ ИЗМЕНЕНИЕ/фикс? ("Не сломали ли это?")	Не сломало ли новое изменение/фикс СТАРЫЕ функции? ("Не сломали ли всё остальное?")</p>
                       <p> Когда выполняется	После КАЖДОЙ новой сборки.	После конкретного исправления/изменения, перед регрессом (если время ограничено).	После исправления багов или добавления нового функционала, на стабильной сборке (прошедшей smoke).</p>
                      <p>  Объем	Минимальный набор критичных функций.	Узконаправленный набор, связанный с изменением.	Широкий: Все функции, затронутые изменениями (или даже весь продукт).</p>
                       <p>  Глубина	Очень поверхностная. Работает ли вообще?	Поверхностная/средняя. Корректна ли конкретная доработка?	Глубокая. Проверка на уровне функциональных, интеграционных тестов, часто с граничными значениями.</p>
                       <p> Скорость	Очень быстро (минуты/десятки минут).	Быстро (часы).	Долго (часы/дни).</p>
                        <p>Обязательность	Обязателен для каждой сборки.	Не всегда. Используется при нехватке времени на полный регресс.	Обязателен после изменений, но только на стабильных сборках.</p>
                       <p> Кто выполняет	Тестировщики / Разработчики.	Тестировщики.	Тестировщики.</p>
                        Главный вывод: Smoke — это ворота для новой сборки. Если сборка их не прошла, Sanity и Регресс к ней даже не приступают!</p><br>
                    <p class="content-text">🛠️ Как выполняется Smoke-тест? (уточнения)
                      </p>1. Получена новая сборка (версия программы).
                      </p>2. Выбирается минимальный набор тест-кейсов:
                    <p>Самые критичные для работы приложения (без них пользователь не сможет вообще ничего сделать).</p>
                    <p> Часто помеченные как Priority: High и Severity: Critical.</p>
                    <p> Основные пользовательские сценарии: Вход, Основное действие приложения (просмотр ленты, создание заказа), Выход.</p>
                     <p>Ключевые интеграции: Отправка письма, скачивание файла, отображение карты (проверяем, что модуль подключен и базовая функция работает, а не все детали).</p>
                     <p>3. Быстрое выполнение: Тест-кейсы запускаются последовательно и оперативно.</p>
                    <p>4. Фиксация результата:</p>
                    <p> Все кейсы PASSED: Сборка стабильна -> Запускаем дальнейшее тестирование (регресс, функциональное, и т.д.).</p>
                    <p> Хотя бы один кейс FAILED: Сборка НЕСТАБИЛЬНА -> Тестирование останавливается -> Отчет разработчикам -> Ожидание новой, исправленной сборки -> Повторный Smoke.</p>
                     5. Документирование: Результаты фиксируются в системе управления тестированием (Jira, TestRail и т.д.), часто с наглядными диаграммами.</p><br>
                    <p class="content-text">🔥 Заключение: Smoke-тест — это твой первый и главный стражник при получении новой версии программы. Он быстро и дешево отсеивает совсем сломанные сборки, не давая команде тратить силы впустую. Это фундамент эффективного процесса тестирования. </p><br>
                </div>

                <h3 class="subsection-title">Регрессионное тестирование</h3>
                <div class="content-card">
                   <p class="content-text">— это проверка того, что новые изменения в коде (исправление багов, добавление фич, обновления) НЕ сломали существующий, ранее работавший функционал. Это критически важный вид тестирования для поддержания стабильности продукта.</p>
                    <p class="content-text">Простыми словами: Представь, что программа — это большой конструктор. Когда ты добавляешь новую деталь (изменение), нужно проверить, что все старые детали по-прежнему работают как надо и ничто не развалилось. Вот это и есть регресс!</p><br>
                    <p class="content-text">🔍 Почему это НЕОБХОДИМО? (Суть проблемы)
                     <p>Побочные эффекты: Исправляя один баг или добавляя новую функцию, разработчики непреднамеренно могут задеть соседний код и сломать то, что работало.</p>
                     <p>Пример из жизни:</p>
                     <p> Было: Кнопка "Купить" работала.</p>
                     <p>Добавили: Новый способ оплаты "Криптовалютой".</p>
                     Регресс: Проверяем, не сломалась ли старая оплата картой после этого изменения.</p><br>
                    <p class="content-text">⚙️ Когда выполняется регрессионное тестирование?
                   <p>После любых изменений в коде:</p>
                   <p>Исправление багов</p>
                   <p>Добавление нового функционала</p>
                   <p>Изменение конфигурации (ОС, библиотеки, БД)</p>
                   <p>Рефакторинг кода (улучшение структуры без изменения функциональности)</p>
                   <p>На стабильной сборке: Только после успешного Smoke-теста (чтобы не тратить время на заведомо сломанную версию).</p><br>
                    <p class="content-text">📋 Что именно проверяется? (Объем регресса)
                  <p>Весь затронутый функционал: Не обязательно тестировать ВСЕ приложение! Фокус — на областях, которые могли пострадать от изменений.</p>
                  <p>Критические сценарии: Основные пользовательские пути (например: регистрация → вход → покупка).</p>
                  <p>Связанные модули: Если меняли код корзины, проверяем не только её, но и интеграцию с каталогом, оплатой, историей заказов.</p>
                   Ранее найденные баги: Особенно те, что были рядом с измененной областью ("а не вернулся ли старый баг?").</p><br>
                    <p class="content-text">🧩 Стратегии выбора тестов для регресса (Как не утонуть в тысячах тест-кейсов?)
                  <p>1. Полный регресс (Full Regression):</p>
                   <p>Проверяется ВСЁ.</p>
                   <p>Когда: После очень больших изменений (смена архитектуры) или перед крупным релизом.</p>
                   <p> Минус: Дорого и долго.</p>
                  <p>2. Частичный регресс (Partial/Selective Regression):</p>
                   <p>Проверяются ТОЛЬКО области, связанные с изменениями + "зоны риска".</p>
                    <p>Как выбрать: Анализ зависимостей (какие модули затронуты?), приоритеты функциональности, история багов.</p>
                     <p> Инструмент: Матрица трассируемости (Traceability Matrix) — показывает связь тестов с требованиями/модулями.</p>
                    <p>3. Повторное тестирование (Re-testing):</p>
                   <p> Только исправленные баги: Проверяем, что конкретный дефект починен.</p>
                     Это НЕ регресс! Регресс — проверка того, что не сломалось то, что не меняли.</p><br> 
                    <p class="content-text">⚖️ Регресс vs Smoke vs Sanity (Ключевые отличия)
                    <p>Критерий	Smoke-тест	Sanity-тест	Регрессионное тестирование</p>
                     <p>Цель	"Жива ли сборка?" (готовность к тестированию)	"Работает ли КОНКРЕТНОЕ изменение?"	"Не сломали ли СТАРОЕ при внедрении НОВОГО?"</p>
                     <p>Объем	Минимум критичных функций	Узкий фокус на изменении	Широкий (затронутые + смежные области)</p>
                    <p>Глубина	Очень поверхностно	Поверхностно/средне	Глубоко (граничные значения, интеграции)</p>
                   <p>Когда	Каждая новая сборка	После конкретного изменения	После изменений на стабильной сборке</p>
                    Автоматизация	Часто автоматизирован	Редко	Крайне желательна! (основной кандидат)</p><br>
                    <p class="content-text">🤖 Почему автоматизация регресса — это спасение?
                    <p>Объем: Ручной регресс на больших проектах может занимать дни или недели. Автотесты запускаются за часы/минуты.</p>
                   <p>Частота: Изменения вносятся постоянно — нужны регулярные проверки.</p>
                   <p>Надежность: Исключает человеческий фактор.</p>
                   <p>ROI (окупаемость): Хотя написание автотестов требует времени, на длинной дистанции они экономят ресурсы.</p>
                     Пример: После каждого коммита в Git запускается Continuous Integration (CI) пайплайн, который прогоняет набор регрессионных автотестов. Разработчик сразу видит, не сломал ли он что-то.</p><br>
                    <p class="content-text">📌 Заключение: Главное о регрессионном тестировании
                    <p>1. "Защита от разрушения": Гарантирует, что новое = хорошо, а старое = по-прежнему хорошо.</p>
                    <p>2. Выполняется ПОСЛЕ изменений: На исправленной/обновленной версии ПО.</p>
                    <p>3. Фокус на "зонах риска": Тестируются области, связанные с изменениями, а не обязательно всё приложение.</p>
                    <p>4. Автоматизация = друг: Без нее регресс на больших проектах становится кошмаром.</p>
                     <p>5. Smoke — вход в регресс: Регресс запускается только если сборка прошла smoke-тест.</p>
                      <p>Аналогия: Представь дорожных рабочих. Они положили новый асфальт на участке (изменение). Регресс — это проверка:</p>
                      <p>Не потрескался ли старый асфальт рядом?</p>
                     <p>Не сдвинулись ли бордюры?</p>
                     <p>Не сломана ли разметка?</p>
                       Работают ли светофоры?</p><br>
                </div>
            </section>

            <!-- Test Classification -->
            <section id="classification" class="content-section">
                <h2 class="section-title">ВИДЫ КЛАССИФИКАЦИИ ТЕСТИРОВАНИЯ</h2>
                <div class="content-card">
                    <p class="content-text">Классификация по уровню тестирования Суть: На каком "слое" или этапе сборки системы проводится тестирование.</p>
                    <p class="content-text">Примеры из статьи:
                  <p>Модульное (Unit): Тестируем отдельные "кирпичики" (функции, классы).</p>
                  <p>Пример: Разработчик пишет тест для функции calculateDiscount(), проверяя, что она правильно считает скидку 10% на сумму 1000 руб.</p>
                  <p>Интеграционное (Integration): Тестируем связи между "кирпичиками".</p>
                  <p>Пример: Проверяем, что модуль "Корзина" корректно передает данные о заказе модулю "Оплата".</p>
                  <p>Системное (System): Тестируем целое здание (приложение) как единое целое.</p>
                  <p>Пример: Проверка всего сценария покупки: поиск товара → добавление в корзину → оформление → оплата → получение чека.</p>
                  <p>Операционное (Release): Тестируем "на стройплощадке" (в боевом окружении) перед сдачей.</p>
                  Пример: Проверка работы приложения на реальном сервере заказчика после установки. 👉 Почему важно: Показывает этап разработки и масштаб тестирования (от детали к целому).</p><br>
                    <p class="content-text">👥 2. Классификация по исполнителям тестирования
                     <p>Суть: Кто проводит тестирование и на какой стадии готовности продукта. Примеры из статьи:</p>
                     <p>Альфа-тестирование: Внутреннее тестирование силами компании-разработчика (иногда + ключевые пользователи). Версия сырая, но основное работает.</p>
                     <p>Пример: Ранний доступ к новому мессенджеру для сотрудников IT-отдела.</p>
                     <p>Бета-тестирование: Тестирование реальными пользователями "в поле". Версия почти готова, нужна обратная связь.</p>
                     Пример: Публикация мобильного приложения в TestFlight (iOS) или бета-версии в Google Play для ограниченной аудитории. 👉 Почему важно: Позволяет собрать фидбэк до массового релиза и выявить проблемы в реальных условиях.</p><br>
                    <p class="content-text">⚙️ 3. Классификация по исполнению кода
                    <p>Суть: Запускается ли код программы во время тестирования? Примеры из статьи:</p>
                    <p>Статическое тестирование: Код НЕ запускается. Проверяем "бумаги" (документы, код, требования).</p>
                    <p> Пример:</p>
                    <p> Code Review: Разработчик смотрит код коллеги на предмет ошибок.</p>
                    <p> Анализ ТЗ: Тестировщик ищет противоречия в требованиях ("Поле 'Email' должно быть обязательным, но в макете его нет").</p>
                    <p> Динамическое тестирование: Код запускается. Проверяем работающую программу.</p>
                     Пример: Любое кликание по интерфейсу, отправка запросов через API, нагрузочные тесты. 👉 Почему важно: Статическое тестирование находит ошибки на ранних этапах (дешевле исправить!), динамическое — как система ведет себя в действии.</p><br>
                    <p class="content-text">➕➖ 4. Классификация по позитивности сценария
                     <p>Суть: Какие данные и действия использует тест. Примеры из статьи:</p>
                     <p>Позитивное тестирование: Используем ТОЛЬКО корректные данные. Проверяем, что система делает то, что должна.</p>
                     <p>  Пример: Ввод валидного email user@example.com в поле регистрации → Ожидаем: успешная регистрация.</p>
                     <p>Негативное тестирование: Используем хотя бы один некорректный параметр. Проверяем, как система обрабатывает ошибки.</p>
                     Пример: Ввод email без "@" (userexample.com) → Ожидаем: сообщение "Неверный формат email". 👉 Почему важно: Позитивные тесты подтверждают работоспособность, негативные — надежность и защиту от "кривых рук" пользователя.</p><br>
                    <p class="content-text">⏳ 5. Классификация по хронологии выполнения
                     <p>Суть: Когда и зачем выполняется тестирование в процессе разработки/поддержки. Примеры из статьи:</p>
                     <p>Повторное (Re-testing / Confirmation): Перепроверяем ОДИН конкретный баг после его исправления.</p>
                    <p>   Пример: Баг "Кнопка 'Отправить' не работает в Firefox" → Разработчик починил → Тестировщик проверяет ТОЛЬКО эту кнопку в Firefox.</p>
                    <p>Регрессионное (Regression): Проверяем, что новое изменение/фикс НЕ сломало СТАРОЕ (то, что не меняли).</p>
                    <p>  Пример: После добавления оплаты криптовалютой → Проверяем, что оплата картой, Apple Pay и создание заказа ВСЕ ЕЩЕ работают.</p>
                    <p>Приёмочное (Acceptance): Финальная проверка заказчиком/бизнесом, что система соответствует их нуждам.</p>
                      Пример: Демонстрация заказчику полного цикла работы системы перед запуском в продакшн. 👉 Почему важно: Показывает цель тестирования на разных этапах: подтвердить фикс (re-test), защитить от поломок (regression), получить одобрение (acceptance).</p><br>
                    <p class="content-text">🧩 Итоговая таблица 5 классификаций:
                    <p>Классификация	Виды тестирования	Ключевой вопрос</p>
                     <p>1. По уровню	Модульное, Интеграционное, Системное, Операционное	На каком масштабе тестируем? (функция → модули → система → продакшн)</p>
                     <p>2. По исполнителям	Альфа, Бета	Кто тестирует и насколько продукт готов?</p>
                     <p>3. По исполнению кода	Статическое, Динамическое	Запускаем ли программу?</p>
                     <p>4. По позитивности	Позитивное, Негативное	Какие данные используем? (валидные vs невалидные)</p>
                     5. По хронологии	Повторное, Регрессионное, Приёмочное	Когда и зачем запускаем тесты?</p><br>
                    <p class="content-text">🔥 Важно запомнить:
                    <p>Эти классификации пересекаются! Один и тот же тест может быть, например:</p>
                    <p>Динамическим (код запущен),</p>
                    <p>Негативным (ввели плохие данные),</p>
                    <p>Системным (проверяем весь сценарий),</p>
                    <p>Регрессионным (после изменений).</p>
                     Знание классификаций помогает четко ставить задачу ("Нужно провести негативное интеграционное тестирование модуля оплаты") и структурировать процесс.</p><br>
                 </div>

                <h3 class="subsection-title">Сколько всего бывает видов тестирования?</h3>
                <div class="content-card">
                    <p class="content-text">Точного числа НЕТ. И вот почему:</p>
              <p>Виды тестирования — это не список из N пунктов. Это многомерная классификация, как кубик Рубика. Один и тот же тест можно описать с разных сторон, используя разные "оси" (критерии) классификации..</p>
                    <p class="content-text">Представь фотоаппарат с фильтрами: Один и тот же пейзаж (тест) можно сфотографировать с разными настройками (вид тестирования). Вот основные "фильтры" (оси классификации) из статьи:
                <p>🥇 По ЦЕЛИ (Что проверяем?):</p>
                      <p>Функциональное: Работает ли функция правильно? (Например: кнопка "Купить" добавляет товар в корзину).</p>   
                    <p>Нефункциональное: КАК работает система? (Например: как быстро грузится страница (Производительность), выдержит ли 1000 пользователей (Нагрузочное), удобен ли интерфейс (Usability), безопасно ли (Security)).</p>
                      <p>Связанное с изменениями: Проверяем последствия изменений.</p>
                       <p> Дымовое (Smoke): Быстрая проверка ОСНОВНЫХ функций после сборки ("дымит" ли вообще?).</p>
                        <p> Регрессионное (Regression): Проверяем, что НОВОЕ или ИСПРАВЛЕННОЕ не сломало СТАРОЕ.</p>
                        <p> Повторное (Re-testing): Проверяем конкретно ИСПРАВЛЕННЫЙ баг.</p>
                         Приемочное (Acceptance): Удовлетворяет ли система бизнес-требованиям и готова ли к выпуску? (Часто делает заказчик/владелец продукта).</p><br>
                    <p class="content-text">📦 По УРОВНЮ / ГЛУБИНЕ (Где тестируем?):
                        <p> Модульное (Unit): Тестируем ОДИН маленький "кирпичик" (функцию, класс) в изоляции. Делают разработчики.</p>
                       <p> Интеграционное (Integration): Тестируем, как несколько "кирпичиков" (модулей) РАБОТАЮТ ВМЕСТЕ.</p>
                       <p> Системное (System): Тестируем ВСЮ систему ЦЕЛИКОМ, как единое целое (и функциональность, и нефункциональные характеристики).</p>
                       Операционное / Приемочное (Release/Acceptance): Тестирование в БОЕВОЙ среде или финальная проверка перед сдачей заказчику.</p><br>
                    <p class="content-text">👀 По ДОСТУПУ (Что видим внутри?):
                       <p>"Черный ящик" (Black Box): Тестируем ТОЛЬКО через интерфейс (как пользователь). Внутренняя структура и код НЕ видны и НЕ важны. Фокус: соответствие требованиям.</p>
                      <p> "Белый ящик" (White Box): Тестируем, ЗНАЯ код и внутреннюю структуру. Делают разработчики (чаще на Unit уровне). Фокус: покрытие кода, логика.</p>
                     "Серый ящик" (Gray Box): Частичное знание внутренностей (например, структуры БД, архитектуры). Используем это для более "умного" тестирования через интерфейс.</p><br>
                    <p class="content-text">➕➖ По СЦЕНАРИЮ (Какие данные используем?):
                         <p>Позитивное: Проверяем, что система делает то, что ДОЛЖНА, с КОРРЕКТНЫМИ данными/действиями. (Например: верный логин/пароль открывает доступ).</p>
                       Негативное: Проверяем, что система КОРРЕКТНО обрабатывает ОШИБКИ пользователя, НЕкорректные данные или нештатные ситуации. (Например: неверный пароль вызывает сообщение об ошибке, а не падает сервер).</p><br>
                    <p class="content-text">🤖 По СПОСОБУ ВЫПОЛНЕНИЯ (Как запускаем?):
                       <p>Статическое: Анализ БЕЗ запуска программы. Это проверка документов, требований, кода (ревью). Ищем ошибки на ранних этапах.</p>
                        Динамическое: Тестирование ЗАПУЩЕННОЙ программы. Это все тесты, где код выполняется.</p><br>
                    <p class="content-text">🧪 По ТЕХНИКАМ ПРОЕКТИРОВАНИЯ (Как придумываем тесты?): (Это не совсем "вид" в общем смысле, но важный аспект как мы тестируем функциональность)
                         <p>Эквивалентное Разделение (EP)</p>
                        <p>Анализ Граничных Значений (BVA)</p>
                       <p>Таблица Решений (Decision Table)</p>
                      <p> Предугадывание Ошибок (Error Guessing)</p>
                      <p>Тестирование Состояний и Переходов (State Transition)</p>
                         Попарное Тестирование (Pairwise) и др.</p><br>
                    <p class="content-text">👥 По ИСПОЛНИТЕЛЮ (Кто тестирует?):
                        <p>Альфа-тестирование: Внутри компании (разработчики, тестировщики), иногда с привлечением некоторых пользователей. Ранняя стадия.</p>
                       <p>Бета-тестирование: Почти готовая версия у ограниченной группы реальных пользователей "в поле". Сбор фидбека.</p>
                        <p>Таблица-шпаргалка для запоминания "основных фильтров":</p>
                       <p>Критерий (Ось)	Основные Виды	Суть</p>
                      <p>🥇 Цель	Функциональное, Нефункциональное, Регрессионное, Дымовое, Повторное, Приемочное	ЧТО мы проверяем?</p>
                     <p>📦 Уровень / Глубина	Модульное (Unit), Интеграционное, Системное, Приемочное/Операционное	ГДЕ (на каком уровне системы) тестируем?</p>
                     <p>👀 Доступ к коду	Черный Ящик (Black Box), Белый Ящик (White Box), Серый Ящик (Gray Box)	ВИДИМ ЛИ мы код/внутренности?</p>
                     <p>➕➖ Сценарий / Данные	Позитивное, Негативное	КАКИЕ данные/действия используем?</p>
                     <p>🤖 Способ выполнения	Статическое, Динамическое	ЗАПУСКАЕМ ЛИ программу?</p>
                      👥 Исполнитель	Альфа-тестирование, Бета-тестирование	КТО тестирует?</p><br>
                    <p class="content-text">Как это работает на практике (примеры):
                       <p>Тест на вход по логину/паролю:</p>
                        <p>Цель: Функциональное (проверяем функцию авторизации).</p>
                       <p>Уровень: Системное (тестируем всю систему).</p>
                       <p> Доступ: Черный ящик (тестируем через интерфейс, не глядя в код).</p>
                       <p>Сценарий: Может быть и Позитивным (верный пароль -> доступ), и Негативным (неверный пароль -> ошибка).</p>
                      <p> Способ: Динамическое (запускаем приложение, вводим данные).</p>
                       Исполнитель: Тестировщик (Альфа) или Бета-тестер.</p><br>
                    <p class="content-text">Тест скорости загрузки страницы:
                    <p>Цель: Нефункциональное (Производительность).</p>
                        <p>Уровень: Системное.</p>
                       <p>Доступ: Черный ящик (измеряем время отклика снаружи).</p>
                       <p>Сценарий: Позитивное (система должна грузиться быстро).</p>
                     <p>Способ: Динамическое.</p>
                     Исполнитель: Тестировщик/Инженер по производительности.</p><br>
                    <p class="content-text">Проверка функции сложения чисел (разработчиком):
                       <p>Цель: Функциональное.</p>
                       <p>Уровень: Модульное (Unit).</p>
                       <p>Доступ: Белый ящик (разработчик знает код функции).</p>
                       <p>Сценарий: Позитивное (2+2=4), Негативное (проверка обработки ошибок, если передать строку).</p>
                       <p>Способ: Динамическое (запускается юнит-тест).</p>
                        Исполнитель: Разработчик.</p><br>
                    <p class="content-text">Вывод (чтобы навсегда сохранить в голове):
                     <p>Не ищи точное число видов. Его нет, потому что классификация многомерная.</p>
                     <p>Запомни основные "оси" (фильтры): Цель, Уровень, Доступ, Сценарий, Способ, Исполнитель.</p>
                     <p>Любой тест можно описать комбинацией этих критериев. Один тест = несколько "видов" одновременно.</p>
                     <p>Фокус на понимании: Зачем нужен каждый критерий? Что он описывает?</p>
                      На старте QA важнее всего: Функциональное / Нефункциональное, Черный ящик, Позитивное/Негативное, Регрессионное, Дымовое, Системное уровень, Динамическое. Остальное придет с опытом.</p><br>
                    <p class="content-text">Не пытайся выучить ВСЕ виды сразу. Начинай с базовых комбинаций. Когда видишь новый термин ("Нагрузочное", "Usability", "Интеграционное"), спрашивай себя: "По какому критерию это вид? (Цель? Уровень?)". Постепенно мозаика сложится, и ты будешь свободно ориентироваться! Через месяц это покажется элементарным.</p><br>                 
                   </div>

                <h3 class="subsection-title">Пирамида тестирования</h3>
                <div class="content-card">
                    <p class="content-text"> — это не просто картинка, а ключевая стратегия организации автоматизированных (и иногда ручных) тестов. Она отражает оптимальное соотношение усилий, стоимости, скорости и эффективности на разных уровнях тестирования.</p>
                    <p class="content-text">Вот что она главное отражает (и почему это так важно):</p><br>
                    <p class="content-text">1️⃣ Соотношение количества тестов по уровням (Форма = Стратегия!)
                    <p>Широкое основание: Много Unit-тестов (модульных). Они проверяют самые маленькие "кирпичики" кода (функции, методы, классы) изолированно. Должны быть самыми многочисленными.</p>
                     <p>Средняя часть: Меньше Integration-тестов (интеграционных). Они проверяют, как несколько "кирпичиков" (модулей, сервисов, баз данных) работают вместе. Их меньше, чем юнит-тестов.</p>
                      Узкая вершина: Еще меньше System/E2E-тестов (системных/сквозных). Они проверяют работу всей системы ЦЕЛИКОМ через пользовательский интерфейс (UI) или API, имитируя действия реального пользователя. Их меньше всего.</p><br>  
                    <p class="content-text">2️⃣ Зависимость характеристик тестов от уровня (Почему такая форма?)
                    <p>Стоимость создания и поддержки:</p>
                    <p>Unit: 🟢 Низкая. Пишутся быстро (часто разработчиками), требуют мало ресурсов, легко изменять при рефакторинге.</p>
                    <p>Integration: 🟡 Средняя. Требуют настройки взаимодействия компонентов, сложнее unit-тестов.</p>
                    <p>E2E: 🔴 Высокая. Требуют настройки всего окружения (БД, сервера, браузеры), хрупкие (ломаются при малейшем изменении UI/путей), сложные в отладке, долгие в написании и поддержке.</p>
                    <p>Скорость выполнения:</p>
                    <p> Unit: 🟢 Очень быстрые (миллисекунды-секунды на тест). Запускаются тысячами за минуты.</p>
                    <p> Integration: 🟡 Средняя (секунды-десятки секунд на тест).</p>
                    <p> E2E: 🔴 Медленные (секунды-минуты на тест). Запуск полного набора может занимать часы.</p>
                    <p>Изолированность ошибок:</p>
                    <p> Unit: 🟢 Отличная. Тест упал = проблема в конкретной маленькой функции/методе. Быстрая локализация бага.</p>
                    <p> Integration: 🟡 Хорошая. Проблема в взаимодействии конкретных модулей/сервисов.</p>
                    <p> E2E: 🔴 Плохая. Тест упал = проблема где-то в системе (UI, бизнес-логика, БД, сеть, конфиг). Долгая и сложная диагностика.</p>
                    <p>Область покрытия (Scope):</p>
                    <p>Unit: 🟢 Узкая, глубокая. Проверяет правильность реализации маленькой части кода.</p>
                    <p> Integration: 🟡 Средняя. Проверяет корректность взаимодействия и контракты между компонентами.</p>
                      E2E: 🟢 Широкая, поверхностная. Проверяет работоспособность сквозного сценария с точки зрения пользователя. Не проверяет все варианты реализации.</p><br>
                    <p class="content-text">3️⃣ Главные цели Пирамиды (Что она дает?)
                     <p>1. Раннее обнаружение багов: Чем раньше (ниже в пирамиде) найден баг, тем дешевле и быстрее его исправить. Unit-тесты ловят ошибки прямо при написании кода.</p>
                     <p>2. Стабильность и скорость обратной связи: Быстрые unit-тесты дают разработчику мгновенный фидбек о работоспособности его кода. Это основа Continuous Integration (CI).</p>
                      <p>3. Снижение стоимости тестирования: Инвестиции в unit-тесты окупаются значительно быстрее, чем в E2E из-за разницы в стоимости поддержки и скорости.</p>
                      <p>4. Устойчивость к изменениям: Unit-тесты меньше всего зависят от изменений в других частях системы или UI. E2E-тесты очень хрупкие.</p>
                     5. Эффективное покрытие: Пирамида помогает достичь максимального покрытия бизнес-логики (unit + integration) при разумном количестве дорогих и медленных E2E-тестов, которые проверяют ключевые пользовательские сценарии.</p><br>  
                    <p class="content-text">⚠️ Чего НЕ отражает пирамида (Важные нюансы!)
                    <p>Ручное тестирование: Пирамида в первую очередь про автоматизацию. Ручное тестирование (исследовательское, usability, приемочное) обычно находится над или рядом с пирамидой.</p>
                     <p>Точные проценты: Нет магического соотношения "70/20/10". Главное — принцип: много дешевых/быстрых тестов внизу, мало дорогих/медленных наверху.</p>
                      Все виды тестов: Она фокусируется на уровнях (unit, integration, system/e2e), а не на видах по цели (функциональное, нагрузочное и т.д.). Например, performance-тест может быть и unit (скорость метода), и integration (скорость API), и e2e (скорость страницы).</p><br>
                    <p class="content-text">🎯 Ключевые выводы (чтобы навсегда запомнить)
                    <p>Пирамида = Эффективность и Экономия. Это стратегия оптимизации усилий по тестированию.</p>
                    <p>Основание (Unit) — самое важное: Инвестируй в него больше всего. Это твой "щит" от глупых ошибок и основа быстрой разработки.</p>
                    <p>Вершина (E2E) — точечная: Автоматизируй только самые критические пользовательские сценарии. Не пытайся покрыть E2E-тестами всё!</p>
                    <p>Integration — мост: Обеспечивает уверенность, что хорошо протестированные модули правильно работают вместе.</p>
                      Нарушение пирамиды = Проблемы: Если пирамида перевернута (много медленных E2E, мало unit) или выглядит как "песочные часы" (мало unit, много integration, мало E2E) — это сигнал о неэффективном и дорогом процессе тестирования, который будет тормозить разработку.</p><br>  
                    <p class="content-text">Как QA-инженеру: Понимание пирамиды поможет тебе аргументировать, почему команде нужно писать больше unit-тестов, а не пложить хрупкие E2E-скрипты на каждый чих, и как эффективно распределять усилия по автоматизации. Это must-know! 💪</p><br>
                     </div>

                <h3 class="subsection-title">Разбираем по пунктам, опираясь на статью и логику пирамиды</h3>
                <div class="content-card">
                    <p class="content-text">Какие есть уровни в пирамиде тестирования?</p>
                    <p class="content-text">Пирамида обычно включает 4 уровня (снизу вверх):
                   <p>1. Модульное (Юнит) тестирование (Unit Testing): Проверка самых маленьких "кирпичиков" кода (функций, классов, методов) в изоляции.</p>
                   <p>2. Интеграционное тестирование (Integration Testing): Проверка взаимодействия нескольких модулей/компонентов между собой и с внешними системами (БД, сервисы, API).</p>
                     <p>3. Системное тестирование (System Testing): Проверка всей системы целиком на соответствие функциональным и нефункциональным требованиям в целевом окружении.</p>
                    <p>4. Приемочное тестирование (Acceptance Testing / E2E): Финал! Проверка, что система в целом удовлетворяет потребностям пользователя и готова к эксплуатации. Сквозные пользовательские сценарии.</p>
                     Примечание: Некоторые модели объединяют Интеграционное и Системное в один уровень.</p><br>  
                    <p class="content-text">2. Почему одни уровни ВЫШЕ, а другие НИЖЕ? Что это отражает?
                    <p>"Выше" в пирамиде = Ближе к пользователю и бизнесу:</p>
                    <p>  Нижние уровни (Юнит, Интеграция): Фокусируются на технической корректности (правильно ли работает код, взаимодействуют ли модули). Это "внутренняя кухня".</p>
                    <p>Верхние уровни (Системное, Приемочное): Фокусируются на пользовательском опыте и бизнес-ценности (работает ли система в целом как надо, решает ли задачи пользователя). Это то, что видит конечный пользователь или заказчик.</p>
                    <p>Отражает:</p>
                    <p>Абстракцию: От деталей реализации (низ) к целостному поведению (верх).</p>
                   <p> Цель тестирования: От верификации ("построили ли правильно?") к валидации ("то ли построили?").</p>
                     Целевую аудиторию: От разработчиков (низ) к тестировщикам, аналитикам, заказчикам (верх).</p><br>
                    <p class="content-text">3. Почему одни уровни ШИРЕ, а другие УЖЕ? Что это отражает?
                    <p>"Шире" (Основание - Юнит-тесты): Должно быть наибольшее количество тестов.</p>
                    <p>"Уже" (Вершина - E2E): Должно быть наименьшее количество тестов.</p>
                    <p>Отражает ключевые характеристики:</p>
                    <p>Стоимость: Юнит-тесты - дешевые в создании и поддержке. E2E-тесты - очень дорогие.</p>
                    <p> Скорость: Юнит-тесты - очень быстрые (миллисекунды/секунды). E2E-тесты - медленные (секунды/минуты/часы).</p>
                    <p> Стабильность: Юнит-тесты - стабильные (меняются редко). E2E-тесты - хрупкие (ломаются от малейших изменений UI/путей).</p>
                    <p> Локализация ошибок: Юнит-тесты - точная локализация (сломался конкретный метод). E2E-тесты - плохая локализация (сломалось "где-то в системе").</p>
                     Покрытие: Юнит-тесты дают глубокое покрытие логики. E2E дают широкое покрытие сценариев. Нужно много дешевых тестов для покрытия логики и мало дорогих для покрытия ключевых путей пользователя.</p><br>
                    <p class="content-text">4. Распредели уровни пирамиды относительно тестирования чёрного, белого и серого ящика:
                   <p>Модульное (Юнит): Белый ящик (White Box). Тестировщик (обычно разработчик) знает и видит код, проверяет его внутреннюю логику.</p>
                   <p>Интеграционное: Серый ящик (Gray Box). Частичное знание внутренней структуры (например, схемы API, структуры БД, архитектуры сервисов) используется для проектирования тестов, но сами тесты часто выполняются через интерфейсы (API) без прямого доступа к коду взаимодействующих модулей. Иногда может быть Черным ящиком, если тестируется только внешнее поведение связки.</p>
                   <p>Системное: Черный ящик (Black Box). Тестирование только через внешние интерфейсы (UI пользователя, публичное API системы) без знания внутреннего устройства.</p>
                     Приемочное (E2E): Черный ящик (Black Box). Тестирование с позиции конечного пользователя только через UI (или основной API системы), без знания внутренней реализации.</p><br>  
                    <p class="content-text">5. Кто пишет юнит-тесты? Согласно статье: В 99% разработкой модульных тестов занимается разработчик. Это его ответственность за корректность работы написанного им кода. Найденные на этом уровне ошибки обычно исправляются разработчиком сразу, без формальных баг-репортов.</p><br>
                    <p class="content-text">6. К какому уровню можно отнести тестирование API? Тестирование API относится преимущественно к уровню Интеграционного тестирования.
                     <p>Почему? API — это интерфейс для взаимодействия между компонентами, модулями или системами. Тестирование API проверяет, как разные части приложения (или разные приложения) обмениваются данными и корректно работают вместе согласно контракту (спецификации API).</p>
                     Уточнение: Тестирование внутреннего API одного приложения (связь между его сервисами) — чистый интеграционный уровень. Тестирование публичного API системы для внешних потребителей может частично затрагивать и системный уровень, так как проверяет работу системы как единого целого через ее интерфейс.</p><br>
                    <p class="content-text">7. Приведи 2 примера внешних интеграций сайта со сторонней системой:
                    <p>1. Интеграция с Платежным Шлюзом (например, Stripe, PayPal, Сбербанк):</p>
                    <p> Как это работает: Пользователь на сайте выбирает товар, нажимает "Купить", сайт перенаправляет его на страницу платежного шлюза для ввода данных карты. Платежный шлюз обрабатывает платеж и сообщает сайту об успехе или неудаче.</p>
                    <p>Что тестируется (Интеграция): Корректная передача данных о заказе (ID, сумма) на шлюз; корректная обработка ответов от шлюза (успех, ошибка карты, ошибка сети); обновление статуса заказа на сайте после платежа.</p>
                    <p>2. Интеграция с Системой Аутентификации через Соцсети (OAuth, например, вход через Google/Facebook):</p>
                    <p> Как это работает: Пользователь нажимает на сайте "Войти через Google". Сайт перенаправляет пользователя на страницу авторизации Google. После успешного ввода логина/пароля Google и разрешения доступа, Google перенаправляет пользователя обратно на сайт, передавая токен авторизации. Сайт использует этот токен для аутентификации пользователя.</p>
                     Что тестируется (Интеграция): Корректность перенаправления на провайдера (Google/FB); корректная обработка токена, полученного от провайдера; создание/авторизация пользователя на сайте на основе данных от провайдера; обработка ошибок (пользователь отменил авторизацию на стороне провайдера, ошибка сети).</p><br>  
                    <p class="content-text">Ключевой вывод: Пирамида — это стратегия. Понимая, к какому уровню относится тест, его характеристики (стоимость, скорость, стабильность) и кто за него отвечает, ты можешь эффективно планировать тестирование и автоматизацию! </p><br>
                    </div>
            </section>

            <!-- Test Design -->
            <section id="test-design" class="content-section">
                <h2 class="section-title">Тест-дизайн</h2>
                <div class="content-card">
                    <p class="content-text">Представь, что тестируешь печеньку 🍪. Ты не можешь съесть все печеньки на фабрике (это долго и дорого). Тест-дизайн — это искусство выбрать минимум печенек, но проверить ВСЕ возможные проблемы (горит ли духовка? правильный рецепт? не попал ли в тесто гвоздь?).</p>
                    <p class="content-text">🔧 Топ-7 Техник — Кратко и Навсегда:
                     Вот «мастхэв» техник, которые покроют 90% случаев. Запоминай по ключевым словам и аналогиям!</p><br>
                    <p class="content-text">🔁 Эквивалентное Разделение (Equivalence Partitioning — EP)
                    <p>Аналогия: Груши в магазине. Все зеленые груши (один класс) — одинаково спелые? Достаточно проверить одну.</p>
                  <p>Суть: Делим данные на «корзины» (классы), где все значения внутри корзины «ведут себя одинаково». Тестируем по 1 значению из каждой корзины.</p>
                 <p>Пример: Поле «Возраст» (допустимо: 1-100 лет). Корзины:</p>
                   <p>❌ Невалидная: -5, 101, "abc"</p>
                     ✅ Валидная: 1, 50, 100 Тесты: Берем -5, 50, 101 → ищем ошибки на границах!</p><br>  
                    <p class="content-text">⚖️ Анализ Граничных Значений (Boundary Value Analysis — BVA)
                   <p>Аналогия: Мост с ограничением «10 тонн». Проверяем: 9.9т (проезжает), 10т (проезжает?), 10.1т (должен остановиться).</p>
                  <p>Суть: Ошибки любят прятаться на границах! Берем значения: min-1, min, min+1, max-1, max, max+1.</p>
                    Пример: Возраст (1-100 лет). Тесты: 0, 1, 2, 99, 100, 101.</p><br>
                    <p class="content-text">🎲 Таблица Решений (Decision Table)
                   <p>Аналия: Правила скидки в магазине: «Если друг и акция → скидка 30%». Запиши все условия в таблицу!</p>
                     <p>Суть: Когда много условий («если... и... то...»). Строим таблицу, где:</p>
                     <p>Столбцы: Все комбинации условий (Да/Нет).</p>
                   <p>Строки: Действия системы.</p>
                    Пример: Кредит в банке. Условия: «Возраст ≥ 21», «Стаж > 1 года». Таблица покажет: когда одобрить, а когда отказать.</p><br>
                    <p class="content-text">🧩 Попарное Тестирование (Pairwise Testing)
                   <p>Аналогия: Дегустация бургеров 🍔. Не нужно пробовать все комбинации булок+котлет+соусов (100 вариантов). Достаточно проверить, чтобы каждая пара (булка+котлета, котлета+соус...) была хоть раз!</p>
                   <p>Суть: Для 3+ параметров. Резко сокращает тесты, но ловит 70% багов. Инструменты: AllPairs, PICT.</p>
                     <p>Пример: Тест сайта: Браузер (Chrome, Firefox, Safari) × ОС (Windows, macOS) × Язык (RU, EN). Вместо 3×2×2=12 тестов → pairwise даст 6-8.</p><br>
                    <p class="content-text">🔄 Диаграмма Переходов Состояний (State Transition)
                     <p>Аналогия: Кофе-машина ☕: «бросил монету → выбрал кофе → налил → забрал». Если бросить 2 монеты → что будет?</p>
                    <p>Суть: Тестируем системы, где важен порядок действий (логины, банкоматы). Рисуем круги (состояния) и стрелки (действия).</p>
                    Пример: Пароль: Ввод пароля → (верный → доступ) / (неверный → ошибка) → (3 ошибки → блокировка).</p><br>  
                    <p class="content-text">🧪 Сценарии Использования (Use Case Testing)
                    <p>Аналогия: Как пользователь готовит пиццу 🍕 в приложении: «Открыть → Выбрать → Оплатить → Ждать доставку».</p>
                    <p>Суть: Тестируем реальные пользовательские сценарии, а не абстракции. Основано на требованиях.</p>
                     Пример: Для мессенджера: «Регистрация → Добавление друга → Отправка сообщения → Удаление чата».</p><br>
                    <p class="content-text">❓ Тестирование Предположений (Error Guessing)
                     <p>Аналогия: Где споткнется пьяный человек? На ступеньках, в темноте... Думай, как «адвокат дьявола» 😈.</p>
                    <p>Суть: Опыт + интуиция! Примеры:</p>
                    <p> Ввод букв в поле «Номер карты».</p>
                    <p> Нажать «Отправить» 100 раз подряд.</p>
                     Отключить интернет во время платежа.</p><br>
                    <p class="content-text">💡 Как Это Все Не Забыть? Памятка:
                     <p>Шаг 1: Есть простые поля (числа, даты)? → Примени EP + BVA (90% успеха!).</p>
                    <p>Шаг 2: Есть много условий («если А и Б или В»)? → Таблица решений.</p>
                    <p>Шаг 3: Есть десятки комбинаций (цвет, размер, ОС)? → Pairwise (экономия времени!).</p>
                    <p>Шаг 4: Есть сложный поток (регистрация → оплата → доставка)? → Диаграмма состояний или Сценарии.</p>
                     Шаг 5: Думаешь «а что если...»? → Error Guessing (полёт твоей злобной фантазии!).</p><br>
                    <p class="content-text">🚫 Частые Ошибки Новичков:
                     <p>Тестировать «все подряд» → Трата времени.</p>
                    <p>Путать EP и BVA → Запомни: EP = «корзины», BVA = «границы корзин».</p>
                     Игнорировать pairwise → Пишут 100 тестов вместо 10.</p><br>  
                    <p class="content-text">✅ Итог:
                    <p>Тест-дизайн — это научный способ быть ленивым (в хорошем смысле!). Чем лучше техника — тем меньше тестов, но больше багов найдешь! 🐞 Чтобы запомнить на 100%:</p>
                   <p>1. Нарисуй схему «7 техник» на стикере.</p>
                   <p>2. Примени каждую к реальному объекту (микроволновка, приложение VK).</p>
                   <p>3. Расскажи кому-то (можно мне 😊).</p>
                   Держи в голове: «Сначала EP/BVA, потом — комбинаторика, потом — сценарии». У тебя всё получится! 🔥</p><br>
                    </div>

                <h3 class="subsection-title">Эквивалентное Разделение</h3>
                <div class="content-card">
                    <p class="content-text">Как применять технику эквивалентных классов? Пример:</p>
                <p class="content-text">Согласно статье, применение техники эквивалентного разделения (эквивалентных классов) включает следующие шаги:
             <p>1. Разбиение на классы: Исходные данные (входные или выходные значения) разбиваются на группы (классы эквивалентности) на основе какого-либо признака. Ключевой принцип: элементы внутри одного класса должны обрабатываться системой одинаково.</p>
             <p>2. Выбор представителей: Из каждого получившегося класса выбирается одно или несколько значений для тестирования. Предполагается, что если тест с этим значением проходит успешно, то и все остальные значения из этого класса тоже должны работать корректно (и наоборот, если тест падает, то ошибка характерна для всего класса).</p>
            <p>3. Тестирование выбранных значений: Создаются и выполняются тест-кейсы для выбранных значений-представителей каждого класса.</p>
             <p>4. Обработка недопустимых значений: Отдельно выделяются и тестируются классы недопустимых значений.</p>
             <p>Пример из статьи: Расчет стоимости доставки в интернет-магазине</p>
             <p> Условие:</p>
             <p> Доставка $15 для заказов < $100</p>
                <p> Доставка $5 для заказов от $100 до $300</p>
            <p> Бесплатная доставка для заказов >= $300</p>
           <p>Разбиение на классы (допустимые):</p>
              <p>Класс 1: $1 - $99.99 (Ожидаемый результат: доставка $15)</p>
             <p>Класс 2: $100 - $299.99 (Ожидаемый результат: доставка $5)</p>
            <p> Класс 3: $300 и выше (Ожидаемый результат: доставка $0)</p>
            <p>Выбор представителей (например):</p>
             <p>  Класс 1: $50 (ожидаем $15)</p>
               <p> Класс 2: $150 (ожидаем $5)</p>
              <p> Класс 3: $350 (ожидаем $0)</p>
               <p>Дополнительно (Недопустимые классы - пример из статьи):</p>
              <p>Значения < $1 (например, $0, -$10) - ожидаем обработку ошибки.</p>
                 Значения между классами? (Статья явно выделяет недопустимые для каждого класса: для Класса 1 - выше 99.99, для Класса 2 - ниже 100 или выше 299.99, для Класса 3 - ниже 300). На практике часто проверяют границы между классами отдельно (см. анализ граничных значений), но в рамках чистого ЭР статья фокусируется на выборе представителей из середины классов и явно недопустимых значениях.</p><br>
                <p class="content-text">2. В чём польза техники эквивалентных классов для нас как для тестировщика?
               <p>Статья четко указывает основные преимущества (пользу) применения этой техники для тестировщиков:</p>
              <p>1. Сокращение количества тестов: Главная польза. Вместо тестирования всех возможных значений (что часто нереально) тестируется лишь небольшое количество представителей из каждого класса. Это экономит значительное время и ресурсы.</p>
              <p>2. Обеспечение широкого охвата (покрытия): Несмотря на меньшее количество тестов, техника позволяет покрыть тестами все выделенные классы данных, что дает уверенность в проверке основных вариантов поведения системы.</p>
              <p>3. Структурированный подход: Дает четкую методику ("набор рекомендаций") для работы с большими объемами входных данных или множеством одинаковых вариантов ввода, помогая избежать хаотичного тестирования.</p>
              4. Эффективность при больших объемах данных: Особенно полезна в ситуациях, где есть очень много возможных входных значений, которые логически можно сгруппировать.</p><br>
                <p class="content-text">3. О чём гласит техника граничных значений?
                <p>Статья определяет анализ граничных значений (АГЗ) следующим образом:</p>
             <p>1. Основа на ЭР: Техника чем-то похожа на эквивалентное разделение и даже основана на нем (разбиение данных на классы).</p>
             <p>2. Фокус на границах: Ключевое отличие от ЭР. Вместо тестирования любых представителей класса, АГЗ фокусируется на тестировании значений, находящихся на "границах" этих классов. Это:</p>
              <p> Минимальные и максимальные допустимые значения в классе.</p>
              <p> Значения непосредственно за этими границами (т.е. недопустимые значения, соседствующие с границей).</p>
               3. Причина: Логика техники исходит из наблюдения, что ошибки наиболее вероятны именно на границах между классами эквивалентности или на предельных значениях. Это особенно актуально для интеграционного тестирования, где ошибки часто возникают на "стыках" модулей.</p><br>
                <p class="content-text">4. Пример из статьи (Продолжение примера с доставкой):
               <p>Для класса $1 - $100 тестируются:</p>
                <p>   Допустимые границы: $1.00 (мин.), $1.01 (чуть выше мин.), $99.99 (макс.)</p>
                <p>   Недопустимые границы: $0.99 (чуть ниже мин.), $100.00 (граница/начало след. класса), $100.01 (чуть выше границы).</p>
               <p>Для класса $100 - $300:</p>
               <p>  Допустимые границы: $100.00, $100.01, $299.99</p>
               <p>  Недопустимые границы: $99.99, $300.00</p>
                <p>Для класса $300 и выше:</p>
               <p>  Допустимые границы: $300.00, $300.01</p>
                Недопустимые границы: $299.99</p><br>
                <p class="content-text">Итог по АГЗ: Техника гласит, что для эффективного поиска ошибок необходимо тестировать не просто представителей классов, а специфические значения на краях этих классов и сразу за ними, так как именно там риск дефектов наиболее высок.</p><br>
                </div>

                <h3 class="subsection-title">Техника граничных значений</h3>
                <div class="content-card">
                    <p class="content-text">Суть техники граничных значений (Boundary Value Analysis - BVA): Это техника тест-дизайна (метод «черного ящика»), которая фокусируется на проверке значений входных данных, находящихся на границах допустимых диапазонов или классов эквивалентности. Она основана на наблюдении, что большинство ошибок в программах возникает именно при обработке пограничных значений, а не в середине диапазона.</p>
                <p class="content-text">Ключевые идеи:
               <p>1. Цель: Обнаружить дефекты, связанные с некорректной обработкой значений на переходах между допустимыми и недопустимыми областями (например, ошибки в операторах сравнения >, >=, <, <=).</p><br>
                <p>2. Что тестируется:</p>
                <p> Минимальные допустимые значения.</p>
                 <p>  Максимальные допустимые значения.</p>
                 <p>  Значения непосредственно выше максимального (max+1).</p>
                 <p>  Значения непосредственно ниже минимального (min-1).</p>
                 <p>  (Иногда также включают значения внутри границ, близкие к min/max, например min+1 и max-1).</p><br>
                <p>3. Дополнение к Эквивалентному Разбиению (EP): BVA логично дополняет технику эквивалентного разбиения. Если EP выделяет классы данных (допустимые/недопустимые), то BVA говорит: "Особенно тщательно проверь значения на границах этих классов".</p><br>
               <p>4. Порядок применения (согласно статье):</p>
               <p>  Определение границ: Найти минимальное и максимальное допустимые значения для входного параметра (из требований, спецификаций).</p>
              <p> Выделение значений: Выбрать тестовые значения:</p>
                <p>  min - 1 (нижняя недопустимая граница)</p>
               <p>   min (нижняя допустимая граница)</p>
               <p>   min + 1 (чуть выше нижней границы)</p>
              <p>   max - 1 (чуть ниже верхней границы)</p>
                 <p>   max (верхняя допустимая граница)</p>
                <p>   max + 1 (верхняя недопустимая граница)</p>
               <p> Проектирование тестов: Создать тест-кейсы, использующие эти значения.</p><br>
                <p>5. Пример:</p>
                 <p> Поле "Возраст" принимает значения от 18 до 65 лет (включительно).</p>
                 <p> Граничные значения для тестирования:</p>
                 <p> 17 (min-1, недопустимое)</p>
                 <p> 18 (min, допустимое)</p>
                  <p>  19 (min+1, допустимое)</p>
                  <p>  64 (max-1, допустимое)</p>
                  <p>   65 (max, допустимое)</p>
                  <p>  66 (max+1, недопустимое)</p>
                  <p>Проще говоря: Если в программе есть условие "от А до Б", техника граничных значений заставляет проверить:</p>
                  <p>Что будет, если ввести ровно А?</p>
                   <p>Что будет, если ввести ровно Б?</p>
                  <p>Что будет, если ввести чуть меньше А (А-1)?</p>
                 <p>Что будет, если ввести чуть больше Б (Б+1)?</p>
                  <p>(И часто также чуть больше А (А+1) и чуть меньше Б (Б-1)).</p>
                   Эта техника помогает находить распространенные ошибки, связанные с неверными условиями в коде (например, вместо >= стоит >), и является очень эффективной при относительно небольшом количестве тестов.</p><br>
                <p class="content-text">Запомнить, что для применения техники граничных значений для начала нужно определить шаг на диапазоне наших значений.
                 <p>ШАГ - это минимальная разница между двумя соседними значениями на диапазоне. Например, мы тестируем зависимость скидки от суммы корзины в интернет-магазине. До 100 рублей - скидка 0%, от 100 рублей и выше - скидка 5%</p>
                    <p>В российском интернет-магазине шаг будет равен 1 рублю, потому что цен в копейках у нас не бывает. Поэтому проверять будем значения 99 рублей, 100 рублей, 101 рубль.</p>
                    <p>В белорусском интернет-магазине цены будут отображаться с точностью до копейки, поэтому на границе мы будем проверять значения 99.99 рублей, 100 рублей и 100,01 рубль</p>
                    Когда приводишь пример применения техники граничных значений - всегда озвучивай или уточняй у собеседующего, какой шаг не диапазоне.</p><br>
                </div>

                <h3 class="subsection-title">Техника попарного тестирования</h3>
                <div class="content-card">
                    <p class="content-text">1. О чём гласит техника попарного тестирования?
                    <p>Статья определяет попарное тестирование следующим образом:</p>
                    <p>1. Основа на комбинаторике: Техника базируется на математических алгоритмах и принципах комбинаторики.</p>
                    <p>2. Тестирование пар параметров: Суть техники заключается в том, чтобы создавать тестовые сценарии, в которых каждое возможное значение одного параметра комбинируется хотя бы один раз с каждым возможным значением всех остальных параметров. То есть, покрываются все уникальные пары значений между разными входными параметрами.</p>
                    <p>3. Цель - покрытие комбинаций: Она позволяет протестировать огромное количество комбинаций входных данных, но делает это не путем перебора всех возможных вариантов, а за счет умного подбора пар.</p>
                    <p>4. Сложность расчетов: Статья подчеркивает, что эта техника считается самой сложной и запутанной из описанных пяти именно из-за необходимости производить нетривиальные комбинаторные расчеты для построения оптимального набора тестов. Часто для этого используются специальные инструменты (Pairwise Tools).</p>
                      Главный постулат техники: Для выявления большинства ошибок, связанных с взаимодействием параметров, достаточно проверить все возможные пары их значений, а не все возможные комбинации всех значений сразу. Это радикально сокращает количество необходимых тестов.</p><br>
                <p class="content-text">2. В каких случаях нужно применять технику попарного тестирования?
                <p>Статья четко указывает основной сценарий применения:</p>
                <p>1. Системы с множеством параметров и их значений: Техника незаменима, когда тестируемая функция/система имеет большое количество входных параметров (переменных), каждый из которых может принимать несколько возможных значений.</p>
                <p>2. Нереальность полного перебора: Попарное тестирование применяется именно тогда, когда тестирование всех возможных комбинаций всех значений всех параметров практически невозможно или нецелесообразно из-за экспоненциально растущего их количества (как в примере ниже).</p>
                <p>3. Пример из статьи: Система онлайн-заказа выпечки имеет параметры:</p>
                <p> Заказ (2 значения: Яблочный пирог, Чизкейк)</p>
                <p> Размер (3 значения: Маленький, Средний, Большой)</p>
                 <p> Город (3 значения: Нью-Йорк, Лос-Анджелес, Чикаго)</p>
                 <p> Количество (3 значения: 1, 2, 3)</p>
                 <p>Доставка (2 значения: Адресная, Самовывоз)</p>
                 <p>Время (2 значения: Немедленно, К указанному времени)</p>
                  Общее число комбинаций: 2 x 3 x 3 x 3 x 2 x 2 = 216. Тестировать все 216 сценариев слишком долго и ресурсозатратно. Это и есть случай, когда нужно применять попарное тестирование.</p><br>
                <p class="content-text">3. В чём польза техники попарного тестирования для нас как для тестировщика?
                <p>Статья выделяет ключевые преимущества (пользу) этой техники для тестировщиков:</p>
                 <p>1. Кардинальное сокращение количества тестов: Это главная польза. Техника позволяет резко уменьшить число необходимых тестовых сценариев по сравнению с полным перебором всех комбинаций, сохраняя при этом высокое покрытие.</p>
                 <p>2. Обеспечение широкого покрытия взаимодействий: Несмотря на меньшее количество тестов, техника гарантирует, что протестированы все возможные парные комбинации значений разных параметров. Это эффективно для поиска дефектов, возникающих из-за взаимодействия двух конкретных параметров (что является очень частой причиной ошибок).</p>
                 <p>3. Оптимальное использование ресурсов: Позволяет охватить тестовыми сценариями максимум фич и при этом потратить минимальное время на тестирование. Это делает процесс QA гораздо более эффективным и экономичным.</p>
                  4. Пример эффективности из статьи: В примере с пекарней (216 возможных комбинаций) применение попарного тестирования с помощью инструмента позволило сократить необходимое количество тестовых сценариев до всего 17, при этом покрывая все возможные пары значений параметров. Это огромная экономия усилий (216 vs 17!).</p><br>
                <p class="content-text">Итог по попарному тестированию: Это мощная, хотя и математически сложная, техника для тестирования систем с множеством комбинируемых параметров. Ее применение дает максимальную отдачу в виде широкого покрытия потенциальных дефектов взаимодействия при минимально необходимом количестве тестовых случаев. Для расчета оптимальных наборов пар обычно используются специализированные инструменты.</p><br>
                </div>

                <h3 class="subsection-title">Схема переходов и состояний</h3>
                <div class="content-card">
                    <p class="content-text">Что такое схема переходов и состояний (Диаграмма переходов состояний)?</p>
                <p class="content-text">Схема (диаграмма) переходов состояний — это визуальное представление (рисунок, схема), которое используется в рамках техники тест-дизайна "Переход состояний". Вот ключевые аспекты:
               <p>1. Отображение состояний: Она визуализирует различные состояния, в которых может находиться программа или система в разные моменты времени и на разных этапах её использования. Каждое состояние обозначается блоком (например, "Состояние 1: Клик на 'Войти'").</p>
               <p>2. Отображение переходов: Она показывает как система переходит из одного состояния в другое в ответ на какие-либо события или входные данные. Эти переходы обозначаются стрелками между блоками состояний.</p>
               <p>3. Цель - Упрощение и Покрытие: Главная цель создания такой схемы:</p>
               <p> Упростить восприятие: "Визуальную информацию воспринимать проще, чем текст". Схема помогает быстрее и нагляднее понять логику работы системы, особенно когда состояний и переходов много.</p>
               <p>Обеспечить максимальное покрытие: "Техника перехода состояний позволяет быстрее получить максимальное тестовое покрытие". Имея перед глазами полную схему, тестировщик может легко увидеть все возможные пути (последовательности состояний) и убедиться, что каждый из них покрыт тестами.</p>
               <p>Структурировать тесты: Схема служит основой для создания тест-кейсов. Позволяет "правильно связать состояния" и "упорядочить данные лаконично и удобно — например, в виде таблицы".</p>
               <p>4. Эффективность: Метод "эффективен при создании наборов тестов для систем со множеством вариаций состояний" и "вам пригодится для тестирования последовательности событий с конечным числом входных параметров".</p>
               <p>5. Пример из статьи: Тестирование системы входа с ограниченным количеством попыток ввода пароля:</p><br>
               <p> Состояния (Блоки): Клик на "Войти", 1-я попытка, 2-я попытка, 3-я попытка, Вход в систему, Блокировка.</p>
               <p>Переходы (Стрелки): Определяются вводом правильного или неправильного пароля. Например:</p>
               <p>Из состояния "Клик на 'Войти'" ввод неверного пароля ведет в состояние "1-я попытка".</p>
               <p>Из состояния "1-я попытка" ввод верного пароля ведет в состояние "Вход в систему".</p>
               <p> Из состояния "3-я попытка" ввод неверного пароля ведет в состояние "Блокировка".</p><br>
               <p>Итог: Схема переходов состояний — это наглядный инструмент (диаграмма), используемый в технике "Переход состояний" для моделирования возможных состояний системы и переходов между ними, что значительно упрощает проектирование тестов с высоким покрытием для сложных систем с последовательностями событий.</p><br>
                </div>

                <h3 class="subsection-title">Исследовательское тестирование</h3>
                <div class="content-card">
                    <p class="content-text">Что такое исследовательское тестирование (Exploratory Testing)?</p>
                <p class="content-text">1. Суть: Исследовательское тестирование — это подход к тестированию ПО, при котором проектирование тестов, их выполнение и анализ результатов происходят параллельно и динамически в течение одной сессии тестирования. Это неформальная, гибкая и когнитивно-нагруженная деятельность, сильно зависящая от навыков и опыта тестировщика.</p>
                <p>2. Контраст с формальными техниками (из статьи): В отличие от описанных в статье техник тест-дизайна (Эквивалентное Разделение, Анализ Граничных Значений и т.д.), которые фокусируются на предварительном структурированном создании тест-кейсов на основе спецификаций или моделей, исследовательское тестирование:</p>
                <p>Не требует предварительных сценариев: Тестировщик не пишет детальные тест-кейсы заранее.</p>
                <p>Основано на исследовании: Тестировщик изучает приложение "на лету", используя свои знания, интуицию, креативность и анализ поведения системы в реальном времени.</p>
                <p>Цикл "Учиться-Проектировать-Выполнять-Анализировать": Это ключевой цикл: тестировщик узнает что-то о приложении -> на основе этого проектирует тест (мысленно или набросок) -> немедленно выполняет его -> анализирует результат -> и на основе анализа проектирует следующий тест. Цикл повторяется непрерывно.</p>
                <p>3. Ключевые аспекты:</p><br>
                <p> Ориентация на открытия: Цель — найти неизвестные дефекты, особенно те, которые трудно предсказать формальными методами (логические ошибки, проблемы юзабилити, неочевидные взаимодействия).</p>
                <p> Опыт и Креативность: Крайне важны знания тестировщика о домене, технологиях, типичных ошибках и его способность придумывать нестандартные сценарии.</p>
                <p> Адаптивность: Направление тестирования быстро меняется в зависимости от найденных дефектов, новых идей или наблюдений за поведением системы.</p>
                <p> Контекстная документация: Хотя формальные кейсы не пишутся заранее, тестировщик фиксирует найденные дефекты, ключевые сценарии проверки и свои мысли во время или сразу после сессии (часто в виде заметок, чек-листов или скринкастов).</p>
                <p>4. Когда полезно (Аналогично разделу "Зачем" в статье):</p><br>
                <p>Нет/мало документации: Когда требования неполные, устаревшие или отсутствуют.</p>
                <p> Сложные/новые области: Для изучения незнакомого функционала или поиска дефектов в сложной логике.</p>
                <p> Критичный UX/Юзабилити: Для оценки удобства использования, интуитивности интерфейса.</p>
                <p>После формального тестирования: Как дополнение к сценариям на основе техник тест-дизайна для поиска "пограничных" или неожиданных ошибок.</p>
                <p>Ограниченное время: Позволяет быстро получить представление о качестве и найти критические баги без долгой подготовки.</p>
                <p>5. Пример (Аналогия с примером из статьи): Представим интернет-магазин из статьи (доставка в зависимости от суммы корзины).</p><br>
                <p>Формальный подход (из статьи): Используем Эквивалентное Разделение или Анализ Граничных Значений для проверки расчета стоимости доставки на конкретных значениях (50$, 150$, 350$, границы).</p>
                <p>Исследовательский подход: Тестировщик решает "поисследовать":</p>
                <p>  Что если добавить товар в корзину, перешагнув порог бесплатной доставки ($300), а потом удалить товар, опустив сумму ниже $300? Корректно ли пересчитается доставка?</p>
                <p>  Что если применить промокод, который сильно снизит сумму корзины (из $350 до $50)? Как поведет себя система?</p>
                <p>  Как ведет себя корзина при очень больших суммах (например, $1000000)? Не ломается ли интерфейс?</p>
                <p>  Можно ли обмануть систему, добавив товар на $300, оформив заказ с бесплатной доставкой, а потом отменив часть заказа? Как это обрабатывается?</p>
                <p>  Насколько понятны сообщения о стоимости доставки пользователю на разных шагах оформления?</p>
                <p>Эти сценарии не были предсказаны формальными техниками, но возникли в голове тестировщика в процессе взаимодействия с системой.</p>
                <p>6. Польза для тестировщика (Аналогично разделу "Польза" в статье):</p><br>
                <p>Находит "хитрые" баги: Позволяет обнаружить сложные, неочевидные дефекты, которые ускользают от сценариев.</p>
                <p> Развивает экспертизу: Требует и развивает глубокое понимание продукта, критическое мышление и креативность тестировщика.</p>
                <p> Быстрый старт: Можно начинать тестировать раньше, даже без полных спецификаций.</p>
                <p> Эффективно в неопределенности: Незаменимо при Agile-разработке или когда требования часто меняются.</p>
                <p> Улучшает покрытие реального использования: Помогает проверить, как система ведет себя при непредусмотренном или нестандартном использовании, что ближе к действиям реальных пользователей.</p><br>
                </div>

                <h3 class="subsection-title">Чек-лист vs Тест-кейс</h3>
                <div class="content-card">
                    <p class="content-text">Чек-лист (Checklist) — это СПИСОК ПРОВЕРОК.</p>
                 <p class="content-text"> Суть: Перечень пунктов (часто коротких вопросов или утверждений), которые нужно быстро проверить. Это "напоминалка" для тестировщика.
                <p>Цель: Убедиться, что ключевые функции работают, ничего критичного не сломалось, покрыть основные сценарии без глубокой детализации. Идеален для дымового (Smoke), регрессионного (Regression) или санитарного (Sanity) тестирования.</p>
                <p>Фокус: Что проверить? (Какие функции, сценарии, условия?)</p>
                <p>Структура (Минимальная):</p>
                <p> Уникальный ID (часто)</p>
                <p>Название пункта проверки (Обязательно!)</p>
                <p>Статус (Pass/Fail/Blocked/NA) (Заполняется во время выполнения)</p>
                <p>Гибкость: Высокая. Тестировщик сам решает, как именно проверить пункт. Опыт и креативность приветствуются.</p>
                <p>Пример чек-листа для авторизации:</p>
                <p>CHK-001: Открытие страницы логина.</p>
                <p> CHK-002: Ввод валидного логина/пароля -> Успешный вход.</p>
                <p> CHK-003: Ввод невалидного логина -> Сообщение об ошибке.</p>
                <p> CHK-004: Ввод невалидного пароля -> Сообщение об ошибке.</p>
                <p> CHK-005: Кнопка "Забыли пароль?" открывает восстановление.</p>
                <p> CHK-006: Кнопка "Регистрация" открывает форму регистрации.</p><br>
                </div>

                <h3 class="subsection-title">Обязательные поля тест-кейса</h3>
                <div class="content-card">
                    <p class="content-text">Перечень практически обязательных полей тест-кейса (минимум для воспроизводимости): Уникальный Идентификатор (ID).</p>
                 <p class="content-text">📝 Тест-кейс (Test Case) — это ИНСТРУКЦИЯ ДЛЯ ТЕСТИРОВАНИЯ
                  <p>Суть: Детальная, пошаговая инструкция для проверки конкретного сценария с четкими входными данными и ожидаемым результатом на каждом шаге. Это сценарий, который должен быть воспроизведен дословно.</p>
                <p> Цель: Обеспечить полное, точное и воспроизводимое тестирование сложных сценариев, новых функций, boundary-значений. Идеален для функционального, интеграционного тестирования, проверки требований.</p>
               <p> Фокус: Как проверить? (Какие точные шаги выполнить? Какие точные данные ввести? Что точно должно произойти?)</p>
                <p> Структура (Обязательные + Рекомендуемые): См. предыдущий ответ (ID, Заголовок, Предусловия, Шаги, Ожидаемый Результат, Постусловия, Приоритет, Связь с требованием).</p>
                <p> Гибкость: Низкая. Тестировщик должен строго следовать шагам. Воспроизводимость — ключ!</p>
                <p>  Пример тест-кейса для пункта CHK-002 (Ввод валидного логина/пароля):</p>
                 <p>  ID: TC-AUTH-002</p>
                <p>  Заголовок: Успешная авторизация с валидными учетными данными.</p>
                <p>  Приоритет: High</p>
                <p>  Предусловия:</p>
                <p>     1. Пользователь находится на странице логина (https://example.com/login).</p>
                <p>  2. Существует тестовый пользователь с логином testuser@example.com и паролем SecurePass123!.</p>
                <p>   Шаги:</p>
                <p>   1. В поле "Email или логин" ввести testuser@example.com.</p>
                 <p>    2. В поле "Пароль" ввести SecurePass123!.</p>
                <p>    3. Нажать кнопку "Войти".</p>
                 <p>  Ожидаемый результат:</p>
                 <p>   1. Система аутентифицирует пользователя.</p>
                 <p>   2. Происходит перенаправление на главную страницу пользователя (https://example.com/dashboard).</p>
                 <p>  3. В правом верхнем углу отображается приветствие: "Добро пожаловать, Test User!".</p>
                  <p> Постусловия:</p>
                    1. Нажать кнопку "Выйти".</p><br>
                 <p class="content-text">📊 Ключевые отличия в таблице:
                 <p>Характеристика	Чек-лист (Checklist)	Тест-кейс (Test Case)</p>
                 <p>Суть	Список пунктов для проверки	Пошаговая инструкция для тестирования</p>
                <p>Детализация	Низкая (Что проверить?)	Высокая (Как проверить? Что ожидать?)</p>
                <p>Структура	Простая (Пункт, Статус)	Сложная (ID, Шаги, ОР, Предусловия и т.д.)</p>
                <p>Гибкость выполнения	Высокая (Тестировщик сам выбирает как)	Низкая (Строгое следование шагам)</p>
                <p>Воспроизводимость	Низкая (Зависит от тестировщика)	Высокая (Любой тестировщик получит тот же рез.)</p>
                 <p>Креативность	Требуется (Для поиска как проверить)	Минимальна (Следуй инструкции)</p>
                  <p>Основное назначение	Smoke, Regression, Sanity тестирование	Функциональное, Интеграционное, Новый функционал, Boundary testing</p>
                 Пример аналогии	Список покупок	Кулинарный рецепт</p><br>
                 <p class="content-text">🧠 Когда что использовать?
                 <p>Чек-лист: Когда нужно быстро проверить много ключевых моментов после сборки, перед релизом, при ограниченном времени. Когда тестировщики опытные и понимают как проверить пункт. Для покрытия "верхнего уровня" функционала.</p>
                 Тест-кейс: Когда нужно детально и точно проверить конкретный сложный сценарий, новую функцию, граничные условия. Когда важна полная воспроизводимость (например, для баг-репортов). Когда тестировщики менее опытны. Для формальной трассируемости требований.</p><br>
                 <p class="content-text">🏁 Итог:
                 <p>Чек-лист — это "Что?" (Что проверить? Работает ли базовая функциональность?)</p>
                 <p>Тест-кейс — это "Как?" и "Что ожидать?" (Какими точными шагами проверить конкретный сценарий и какой точный результат должен быть?)</p>
                 <p>Оба инструмента важны и дополняют друг друга в арсенале QA-инженера! Умение выбирать правильный инструмент под задачу — признак профессионализма.</p><br>
                 <p class="content-text">Если поле можно представить отсутствующим в тест-кейсе, и тест-кейс при этом все еще остается понятным, выполнимым и полезным для достижения своей цели (проверки определенного требования/функционала), то такое поле не является абсолютно обязательным.</p><br>
                 <p class="content-text">Однако, есть поля, без которых тест-кейс фактически теряет свой смысл или становится крайне неэффективным, трудновыполнимым или бесполезным. Вот они:</p><br>
                 <p class="content-text">Абсолютно обязательные поля (Без них тест-кейс не имеет смысла):
              <p>1. Уникальный Идентификатор (ID):</p>
              <p> Почему обязательно: Позволяет однозначно ссылаться на тест-кейс в отчетах, баг-репортах, при планировании, в матрице трассируемости. Без ID невозможно управлять множеством тест-кейсов.</p>
             <p>Можно без? Нет. Без уникального ID тест-кейс теряется в массе других, им невозможно управлять.</p><br>
              <p>2. Название / Заголовок (Title):</p>
               <p> Почему обязательно: Кратко и понятно описывает ЧТО именно проверяет этот тест-кейс. Это первое, что видят тестировщик или менеджер. По заголовку сразу должно быть понятно о чем кейс.</p>
              <p>Можно без? Нет. Без заголовка невозможно понять, что проверяет кейс, не отрывая его полностью.</p><br>
              <p>3. Шаги (Steps / Actions):</p>
              <p>Почему обязательно: Четкая последовательность действий, которую должен выполнить тестировщик, чтобы воспроизвести проверку. Это инструкция "КАК" проверить.</p>
              <p>Можно без? Нет. Без шагов тестировщик не знает, что делать. Тест становится субъективным и невоспроизводимым.</p><br>
              <p>4. Ожидаемый Результат (Expected Result):</p>
               <p>Почему обязательно: Описывает ЧТО должно произойти в системе (или как она должна себя вести) после выполнения всех шагов. Это критерий успешности/неуспешности теста.</p>
              <p>Можно без? Нет. Без ожидаемого результата невозможно понять, прошёл тест или упал. Тестирование теряет объективность.</p>
             <p>Условно обязательные / Крайне рекомендованные поля (Технически без них можно, но практика показывает, что лучше не опускать):</p><br>
             <p>1. Приоритет (Priority): (Critical, High, Medium, Low)</p>
              <p>  Почему важно: Помогает планировать тестирование, понимать важность кейса и влияние его падения.</p>
             <p> Можно без? Технически ДА. Можно иметь список кейсов без приоритета. Но это резко ухудшает управление тестированием, особенно при нехватке времени. На практике считается обязательным для эффективности.</p><br>
              <p>2. Предусловия (Preconditions):</p>
              <p> Почему важно: Описывает состояние системы/данных/среды, которое должно быть достигнуто ДО начала выполнения шагов (например, "Пользователь залогинен", "Товар добавлен в корзину", "Установлена версия ПО X.Y").</p>
             <p> Можно без? Технически ДА. Можно попытаться описать все в Шагах. Но это делает шаги громоздкими, дублирует информацию и усложняет поддержку. Практически всегда необходимо для четкости.</p><br>
              <p>3. Постусловия (Postconditions):</p>
              <p> Почему важно: Описывает действия, которые нужно выполнить ПОСЛЕ теста, чтобы вернуть систему/данные в исходное состояние (например, "Удалить тестовый заказ", "Разлогинить пользователя"). Важно для независимости тестов и чистоты данных.</p>
               <p> Можно без? Технически ДА. Но пренебрежение постусловиями ведет к "загрязнению" тестовой среды и взаимозависимости тестов, что является плохой практикой.</p><br>
              <p>4. Связанное требование / Компонент / Модуль:</p>
               <p>  Почему важно: Обеспечивает трассируемость. Позволяет понять, какое функциональное требование или часть системы проверяет этот кейс.</p>
              <p> Можно без? Технически ДА. Можно иметь набор кейсов без явной привязки. Но без трассируемости невозможно полноценно оценить покрытие требований тестами и влияние изменений.</p><br>
                <p>Поля, которые НЕ являются обязательными (но могут быть полезны):</p>
               <p>Автор (Author)</p>
               <p>Дата создания (Date Created)</p>
               <p>Дата последнего изменения (Last Modified)</p>
               <p>Оценка усилий (Estimate)</p>
               <p>Тип теста (Functional, Regression, Smoke, etc.) (хотя часто выносится в набор/сьют)</p>
               <p>Фактический результат (Actual Result) (часто заполняется во время выполнения теста, а не при создании кейса)</p>
               <p>Статус (Status) (Проект, Утвержденный, Устаревший Draft, Approved, Obsolete - обычно управляется в тест-менеджмент системе)</p>
               <p>Тестовые данные (Test Data) (могут быть вынесены отдельно или описаны в Предусловиях/Шагах)</p>
                  Прикрепленные файлы (Attachments) (скриншоты, логи, файлы данных)</p><br>
                 <p class="content-text">Итог:
                <p>Без ID, Заголовка, Шагов и Ожидаемого Результата тест-кейс не может считаться полноценным и выполнимым. Это ядро.</p>
                <p>Поля Приоритет, Предусловия, Постусловия и Связь с требованием являются крайне рекомендованными, практически обязательными в профессиональной среде для эффективности, поддерживаемости и управляемости тестирования. Технически без них кейс может существовать, но его качество и полезность будут низкими.</p>
	               Твой критерий "Можно представить тест-кейс без этого поля?" — это отличный способ определить, является ли поле абсолютно обязательным. Если без поля кейс перестает быть понятным инструкцией для проверки конкретного ожидаемого поведения — поле обязательное.</p><br>
                <p>Чек-лист – твой спасательный круг, чтобы не утонуть в море функционала и ничего не забыть.</p>
                   <p class="content-text"> Тест-кейс – твой точный навигатор, чтобы проверить каждый поворот сложного пути и знать, куда должен привести.</p><br>
                </div>
            </section>

            <!-- Bug Reports -->
            <section id="bug-reports" class="content-section">
                <h2 class="section-title">Баг-репорт</h2>
                <div class="content-card">
                    <p class="content-text">— это главный инструмент коммуникации между тестировщиком и разработчиком (а еще менеджером, дизайнером, аналитиком...). От его качества напрямую зависит, насколько быстро и правильно баг будет исправлен. Давай разбираться по полочкам!</p>
                 <p class="content-text">📌 Базовое определение: Баг-репорт — это документированное описание проблемы (дефекта) в ПО, включающее все детали, необходимые для её понимания, воспроизведения и исправления. Это не просто "ой, тут ошибка!", а структурированная информация.</p>
     <p>🎯 Главная цель баг-репорта: Четко и однозначно донести суть проблемы до разработчика так, чтобы он смог её воспроизвести, понять и исправить, затратив минимум времени на поиски и уточнения.</p>
     <p>📋 Ключевые (ОБЯЗАТЕЛЬНЫЕ) поля баг-репорта (Без них репорт бесполезен):</p><br>
    <p>1. Уникальный ID (Bug ID):</p>
    <p> Зачем: Автоматически присваивается системой трекинга (Jira, Bugzilla и т.д.). Нужен для ссылок, поиска, отслеживания истории.</p>
    <p> Пример: PROJECT-123</p><br>
      <p>2. Краткий и понятный Заголовок (Summary / Title):</p>
    <p> Зачем: Должен сразу дать понять, в чем суть проблемы. Разработчик, глядя на список багов, должен понять суть.</p>
    <p> Как писать: Глагол + Объект + Ошибка. Избегай общих фраз!</p>
    <p> Плохо: "Проблема с кнопкой"</p>
    <p> Хорошо: "Кнопка 'Сохранить' становится неактивной после ввода спецсимвола '#' в поле 'Имя'"</p><br>
       <p>3. Шаги для Воспроизведения (Steps to Reproduce):</p>
    <p> Зачем: САМОЕ ВАЖНОЕ ПОЛЕ! Четкая, последовательная инструкция, как гарантированно вызвать баг. Должна работать у любого, кто ее прочитает.</p>
    <p> Как писать:</p>
      <p>   Пронумерованный список.</p>
      <p>  Максимально конкретно (ссылки, данные, кнопки).</p>
       <p>  Только необходимые шаги.</p>
       <p>  Учитывай предусловия (если критичны).</p>
         <p> Пример:</p>
       <p>  Открыть приложение 'X' (версия 2.1.0).</p>
       <p>  Перейти в раздел 'Профиль'.</p>
       <p>  Нажать кнопку 'Редактировать'.</p>
       <p>  В поле 'Имя' ввести Олег#Петров.</p>
       <p>  Попытаться нажать кнопку 'Сохранить'.</p><br>
        <p>4. Фактический Результат (Actual Result):</p><br>
          <p> Зачем: Описывает, что происходит на самом деле после выполнения всех шагов. Это и есть проблема.</p>
        <p> Как писать: Конкретно, наблюдаемо. Что видишь, что слышишь, что не происходит.</p>
         <p> Пример: "Кнопка 'Сохранить' становится серой (неактивной). Сообщения об ошибке не появляется. Данные не сохраняются."</p><br>
         <p>5. Ожидаемый Результат (Expected Result):</p>
          <p>  Зачем: Описывает, как система ДОЛЖНА была себя вести согласно требованиям, дизайну или здравому смыслу.</p>
          <p>  Как писать: Четко, ссылаясь на требование/дизайн (если возможно).</p>
          <p>  Пример: "Кнопка 'Сохранить' должна оставаться активной. При нажатии данные профиля (включая имя с символом '#') должны сохраниться. ИЛИ: Должно появиться сообщение об ошибке 'Имя не может содержать спецсимволы'."</p><br>
        <p>6. Серьезность (Severity): (НЕ приоритет!)</p>
         <p> Зачем: Оценивает влияние бага на функционал/пользователя/бизнес. Насколько плоха ошибка?</p>
         <p> Шкала (пример):</p>
         <p> Blocker (S1): Система падает, ключевая функция недоступна.</p>
         <p> Critical (S2): Основная функция не работает как надо.</p>
         <p>  Major (S3): Значительная проблема, но есть обходной путь.</p>
         <p>  Minor (S4): Незначительная проблема, не влияет на основной функционал (опечатка, мелкий UI-глюк).</p>
         Trivial (S5): Косметическая проблема.</p><br>
                 <p class="content-text">📌 Важные РЕКОМЕНДУЕМЫЕ поля:
              <p>1. Приоритет (Priority): (НЕ серьезность!)</p>
              <p>Зачем: Указывает очередность исправления бага с точки зрения разработки/релиза (решает менеджер/тимлид). Как срочно фиксить?</p>
              <p> Шкала (пример): P1 (High) -> P2 (Medium) -> P3 (Low). Блокер почти всегда P1, но опечатка может быть Critical (S3) но Low Priority (P3).</p>
              <p>2. Окружение (Environment):</p>
             <p> Зачем: Где баг найден? Помогает локализовать проблему (может воспроизводиться только в специфичных условиях).</p>
              <p>Что указать: ОС и версия (Windows 11 23H2), Браузер и версия (Chrome 125.0), Устройство (iPhone 15 Pro, iOS 17.5), Версия приложения (2.1.0), Сервер (TestEnv), Спец. настройки.</p>
              <p>3. Компонент / Модуль (Component / Module):</p>
             <p>  Зачем: Указывает, в какой части системы баг. Помогает назначить правильного разработчика.</p>
             <p>Пример: Frontend: User Profile, Backend: Auth API, Database: Users.</p>
            <p>4. Прикрепленные файлы (Attachments):</p>
              <p>  Зачем: Скриншоты, видео воспроизведения, логи (консоль, сервер) — очень сильно упрощают жизнь разработчику! "Лучше один скриншот, чем тысяча слов".</p>
             <p>Совет: Выделяй на скриншотах проблемное место (стрелкой, рамкой).</p>
           <p>5. Ссылка на тест-кейс / требование:</p>
               Зачем: Обеспечивает трассируемость. Показывает, на каком тесте упало или какое требование нарушено.</p><br>
                 <p class="content-text">🚫 Чего НЕ должно быть в баг-репорте:
             <p>Эмоций: "Это ужасно!", "Опять эти кривые руки!".</p>
             <p>Оскорблений: В адрес разработчиков, дизайнеров и т.д.</p>
            <p>Домыслов о причинах: "Наверное, забыли проверить на null". (Ты тестировщик, не разработчик. Фиксируй факт).</p>
                <p>Расплывчатости: "Иногда не работает", "Где-то здесь ошибка".</p>
                 Нецензурной лексики.</p><br>
                 <p class="content-text">📝 Пример баг-репорта (свяжем с предыдущим примером авторизации):
                  <p>ID: AUTH-42 (автоматически)</p>
                  <p>Summary: Ошибка 500 при попытке входа с email, содержащим '+' (плюс)</p>
                 <p>Environment: Test Env; Chrome 125.0; Windows 11; App v2.1.0</p>
               <p>Steps to Reproduce:</p>
              <p>1. Открыть страницу входа: https://test.example.com/login</p>
               <p>2. В поле "Email" ввести user+test@example.com</p>
               <p>3. В поле "Password" ввести ValidPass123!</p>
                <p> 4. Нажать кнопку "Sign In".</p>
               <p>Actual Result:</p>
                <p>1. Страница перезагружается.</p>
                <p> 2. Отображается белый экран с текстом "500 Internal Server Error".</p>
                <p> 3. В консоли браузера (F12) ошибка: POST https://test.example.com/api/login 500 (Internal Server Error).</p>
                 <p> 4. Пользователь не авторизован.</p>
                 <p>Expected Result:</p>
                 <p>1. Пользователь успешно авторизуется.</p>
                  <p> 2. Происходит редирект на страницу /dashboard.</p>
                  <p> 3. Отображается приветственное сообщение.</p>
                  <p>Severity: Critical (S2) // Основная функция (логин) недоступна для части пользователей.</p>
                <p>Priority: P1 (High) // Надо чинить срочно!</p>
                <p>Component: Backend: Auth API</p>
                 <p>Attachments:</p>
                 <p> 1. screenshot_error_500.png (скрин белого экрана с ошибкой 500)</p>
                  <p>2. console_logs.txt (логи консоли браузера)</p>
                     Link: Req: AUTH-005 (Поддержка RFC-комплаентных email)</p><br>
                 <p class="content-text">🧠 Ключевые принципы хорошего баг-репорта (Золотые правила):</p>
                      <p>1. Reproducible (Воспроизводимый): Главное! Если разработчик не смог воспроизвести — баг закроют как "Not Reproducible". Шаги должны быть железобетонными.</p>
                      <p>2. Specific (Конкретный): Никакой воды. Только факты, конкретные данные, конкретные экраны.</p>
                      <p>3. Clear (Понятный): Пиши простым языком, избегай двусмысленностей. Используй скриншоты/видео.</p>
                      <p>4. Concise (Лаконичный): Только необходимая информация. Не заваливай ненужными деталями, но и не будь слишком краток.</p>
                      <p>5. Neutral (Нейтральный): Факты, а не эмоции. Ошибка — в коде, а не в разработчике.</p>
                      6. One Bug = One Report (Один баг — один репорт): Не пиши несколько не связанных проблем в один отчет.</p><br>
                 <p class="content-text">Помни, друг: Написание отличного баг-репорта — это навык, который оттачивается практикой. Чем точнее и понятнее твой репорт, тем быстрее команда сделает продукт лучше. Ты — глаза и уши качества!</p><br>
                </div>

                <h3 class="subsection-title">Обязательные поля баг-репорта</h3>
                <div class="content-card">
                    <p class="content-text">Если баг-репорт можно представить понятным, полезным и выполнимым без какого-то поля, значит, это поле не является абсолютно обязательным.</p>
                 <p class="content-text">🔎 Абсолютно обязательные поля баг-репорта (Без них репорт теряет смысл или невыполним):
                   <p>1. Краткий и Понятный Заголовок (Summary / Title):</p>
                   <p>Почему обязательно: Без заголовка невозможно понять суть проблемы с первого взгляда. Разработчик/менеджер, глядя в список багов, не сможет оценить, о чем речь. Репорт становится "слепым".</p>
                  <p>Можно без? НЕТ. Представь список багов с пустым полем "Summary" — это полный хаос.</p>
                 <p>2. Шаги для Воспроизведения (Steps to Reproduce):</p>
                 <p>  Почему обязательно: Это ядро репорта. Без четкой, пошаговой инструкции разработчик не сможет воспроизвести баг и, следовательно, не сможет его исправить. Репорт превращается в бесполезное заявление: "Что-то не работает".</p>
                 <p>  Можно без? НЕТ. Представь репорт без шагов: "На странице логина что-то сломалось". Как разработчик поймет, что именно и как вызвать проблему? Никак. Репорт будет немедленно отклонен или потребует уточнений.</p>
                 <p>3. Фактический Результат (Actual Result):</p>
                  <p>  Почему обязательно: Без описания того, что пошло не так (негативного результата), непонятно, в чем заключается сам дефект. Чем отличается от ожидаемого? Что именно сломалось?</p>
                  <p>v Можно без? НЕТ. Представь: "Выполнил шаги 1-5 (без описания результата)". Разработчик не знает, что считать ошибкой. Это все равно что сказать врачу: "У меня болит" — но не сказать где и как.</p>
                  <p>4. Ожидаемый Результат (Expected Result):</p>
                   <p> Почему обязательно: Без описания того, как система должна была себя вести согласно требованиям, здравому смыслу или дизайну, невозможно понять, почему фактический результат является ошибкой. Это критерий, по которому определяется баг.</p>
                   Можно без? НЕТ. Представь: "После шага 5 кнопка серая (ФР)". Но если по ТЗ кнопка должна быть серой в этом случае? Без ОР разработчик не поймет, нарушено ли ожидаемое поведение.</p><br>
                 <p class="content-text">📌 Почему именно эти 4 поля абсолютно обязательны по твоему критерию?
                 <p>Без любого из них баг-репорт перестает выполнять свою основную функцию: четко, однозначно и воспроизводимо сообщить разработчику о проблеме, чтобы он мог её понять и исправить.</p>
                 Попробуй мысленно убрать любое из этих полей — репорт сразу становится неполным, непонятным или бесполезным.</p><br>
                 <p class="content-text">🛠 Условно обязательные / Крайне рекомендованные поля (Технически без них можно, но качество репорта резко падает):
                  <p>1. Серьезность (Severity):</p>
                  <p>   Почему важно: Помогает понять влияние бага на систему и пользователя. Без нее сложно оценить критичность и планировать исправления.</p>
                  <p> Можно без? Технически ДА. Можно создать репорт без Severity. Разработчик возможно поймет серьезность по описанию. Но это затрудняет приоритизацию и управление багами. На практике почти всегда обязательно.</p>
                 <p>2. Окружение (Environment):</p>
                 <p>  Почему важно: Баг может проявляться только в специфичных условиях (браузер, ОС, версия). Без этой информации разработчик может потратить время впустую, пытаясь воспроизвести в другой среде.</p>
                 <p> Можно без? Технически ДА. Если баг воспроизводится везде или среда по умолчанию известна. Но риск высок: если баг не воспроизведется у разработчика (из-за другой среды), репорт закроют как "Not Reproducible". Сильно рекомендуется всегда указывать!</p>
                 <p>3. Приоритет (Priority):</p>
                  <p> Почему важно: Указывает очередность исправления с точки зрения релиза/ресурсов. Задает сроки.</p>
                  <p> Можно без? Технически ДА. Приоритет часто выставляет не QA, а менеджер/тимлид позже. Репорт без Priority все еще передает суть дефекта. Но без него сложнее управлять процессом исправления.</p>
                  <p>4. Компонент / Модуль (Component/Module):</p>
                 <p> Почему важно: Помогает быстро назначить репорт нужному разработчику или команде.</p>
                 <p> Можно без? Технически ДА. Можно создать репорт без компонента. Но это замедлит его назначение и обработку, особенно в больших проектах.</p>
                 <p>5. Прикрепленные файлы (Attachments):</p>
                 <p> Почему важно: Скриншоты, видео, логи — невероятно упрощают понимание и ускоряют исправление. "Лучше один раз увидеть".</p>
                  Можно без? Технически ДА. Можно описать проблему словами. Но для многих багов (особенно UI, анимации, сложных сценариев) скриншот/видео крайне желательны, а иногда почти обязательны для полного понимания.</p><br>
                 <p class="content-text">🚫 Поля, которые НЕ являются обязательными (но могут быть полезны в системе):
                  <p>Уникальный ID (Bug ID): Часто присваивается автоматически системой (Jira и т.д.). Технически, если пишешь отчет в блокноте, можно без него. Но в реальной работе он жизненно необходим для управления.</p>
                  <p>Автор (Reporter)</p>
                 <p>Дата создания (Date Created)</p>
                 <p>Статус (Status): (New, In Progress, Fixed, Reopen, Closed и т.д.) - обычно управляется системой/процессом.</p>
                 <p>Назначено (Assigned To): - часто назначается позже.</p>
                  <p>Ссылка на требование/тест-кейс (Link to Requirement/Test Case)</p>
                 <p>Версия, в которой найден (Found in Version)</p>
                 Версия, в которой исправлен (Fixed in Version)</p><br>
                 <p class="content-text">🏁 Итог по обязательным полям (по твоему критерию):
                 <p>1. Summary: Без него — непонятно О ЧЕМ баг.</p>
                 <p>2. Steps to Reproduce: Без них — НЕВОЗМОЖНО воспроизвести и исправить баг.</p>
                 <p>3. Actual Result: Без него — непонятно, ЧТО СЛОМАЛОСЬ.</p>
                 <p>4. Expected Result: Без него — непонятно, ПОЧЕМУ это ошибка (как должно было быть).</p>
                 <p>Эти 4 поля — абсолютный минимум, без которого баг-репорт не выполняет свою основную функцию. Попробуй представить репорт без любого из них — он сразу становится бесполезным или требует немедленных уточнений.</p>
                 Поля вроде Серьезность, Окружающая среда, Приоритет, Вложения, Компонент Severity, Environment, Priority, Attachments, Component крайне важны для эффективности и качества коммуникации, но технически репорт может существовать без них (хотя это плохая практика).</p><br>
                 </div>

                 <h3 class="subsection-title">Серьёзность и приоритет бага</h3>
                 <div class="content-card">
                    <p class="content-text">Что такое Серьёзность бага (Severity)?</p>
                 <p class="content-text">Серьёзность (Severity) — это объективная оценка степени влияния дефекта на работоспособность системы, функционал, данные пользователя или бизнес-процессы.</p><br>
                 <p> class="content-text">➔ Отвечает на вопрос: Насколько критична эта ошибка для системы?</p>
                    ➔ Не зависит от срочности исправления! Это характеристика самого бага.</p><br>
                 <p class="content-text">2. Уровни серьёзности бага (Стандартная градация)
                   <p>Уровни могут немного отличаться в компаниях, но основа едина:</p>
                  <p>Уровень	Описание	Примеры</p>
                     <p>Blocker (S1)	Система неработоспособна. Ключевой функционал полностью недоступен, критичные данные теряются. Невозможно продолжить тестирование.	</p>
                     <p>• Сервер падает при запуске. </p>
                    <p>• Кнопка "Оплатить заказ" не реагирует.</p>
                    <p>Critical (S2)	Основной функционал нарушен. Ошибка блокирует ключевые сценарии, но есть обходной путь. Потеря данных или серьёзные риски безопасности.</p>
                   <p>• Пользователь не может зарегистрироваться. </p>
                   <p>• Расчёт суммы заказа неверен.</p>
                   <p>Major (S3)	Существенная проблема. Функционал работает с ошибками, но основная задача выполнима. Нет риска потери данных.	</p>
                     <p>• Не сохраняются настройки профиля. </p>
                    <p>• Часть данных не отображается в отчёте.</p>
                    <p>Minor (S4)	Незначительная проблема. Ошибка не влияет на основной функционал, но ухудшает UX. Обходной путь есть всегда.</p>	
                    <p>• Опечатка в сообщении.</p>
                    <p>• Некритичное поле не валидируется.</p>
                     <p>Trivial (S5)	Косметический дефект. Проблема визуального восприятия, не влияющая на функционал.	</p>
                    <p>• Неправильный отступ в интерфейсе. </p>
                   • Иконка чуть съехала.</p><br>
                 <p class="content-text">3. Что такое Приоритет бага (Priority)?
                  <p>Приоритет (Priority) — это субъективная оценка срочности исправления дефекта с точки зрения бизнеса, релиза или разработки.</p>
                  <p> ➔ Отвечает на вопрос: Как быстро нужно исправить этот баг?</p>
                 <p> ➔ Определяется менеджером/тимлидом на основе: - Серьёзности (Severity), - Влияния на пользователей, - Близости релиза, - Ресурсов команды.</p>
                 <p> ➔ Может не совпадать с серьёзностью! Например:   Опечатка в логотипе (Minor S4) → Приоритет High (P1) – если релиз завтра.</p>
                   Падение сервера в тестовой среде (Critical S2) → Приоритет Low (P3) – если проблема только у тестировщиков.</p><br>
                 <p class="content-text">4. Уровни приоритета бага
                    <p>Приоритет	Описание</p>
                    <p>High (P1)	Исправить немедленно! Блокирует релиз/тестирование, критичен для бизнеса или безопасности.</p>
                  <p>Medium (P2)	Исправить в текущем спринте/цикле. Важная ошибка, но не блокирующая.</p>
                    Low (P3)	Исправить, когда будет время. Не влияет на релиз, можно отложить.</p><br>
                 <p class="content-text">🔑 Ключевые отличия Severity vs Priority
                     <p>Параметр	Серьёзность (Severity)	Приоритет (Priority)</p>
                       <p>Основа	Техническое влияние на систему	Бизнес-срочность исправления</p>
                   <p>Кто ставит	Тестировщик	Менеджер/Тимлид</p>
                   <p>Зависит от	Характера дефекта	Сроков, рисков, ресурсов команды</p>
                  Пример	Blocker (падение сервера)	P3 (если баг в неиспользуемом модуле)</p><br>
                 <p class="content-text">🛠 Практические советы
                  </p>1. Всегда указывай Severity в баг-репорте – это твоя экспертная оценка как QA.</p>
                 </p>2. Priority часто выставляет не тестировщик – но ты можешь предложить свою оценку в комментариях.</p>
                 </p>3. Blocker ≠ High Priority автоматически – если баг найден в старом функционале, который отключат через неделю, его приоритет может быть Low.</p>
                 4. Используй контекст: Один и тот же баг может иметь разный приоритет в мобильном банке (High) и в игре-головоломке (Low).</p><br>
                 <p class="content-text">💡 Пример для закрепления: Баг: На главной странице банка опечатка в слове "Кредит" → "Кридит".
                 </p>Severity: Trivial (S5) (не влияет на функционал).</p>
                 </p>Priority: High (P1) (релиз через день, ошибка бьёт по репутации).</p>
                  Понимание разницы между severity и priority — признак профессионализма! </p><br>
                </div>

                <h3 class="subsection-title">Примеры Severity vs Priority</h3>
                <div class="content-card">
                    <p class="content-text">Пример 1: Высокий приоритет (Priority) + Низкая серьёзность (Severity).</p>
                 <p class="content-text">Баг: На главной странице банковского приложения в слогане опечатка: «Надёжные кридитные решения» вместо «Надёжные кредитные решения».
                 <p>Серьёзность (Severity): Minor (S4) Почему? Функционал не сломан, деньги не теряются, приложение работает. Ошибка чисто визуальная.</p>
                 <p> Приоритет (Priority): High (P1) Почему?</p>
                 <p> Релиз — через 1 день, и клиенты увидят безграмотность;</p>
                 <p> Ошибка бьёт по репутации банка;</p>
                 <p>  Юридические риски: ЦБ может оштрафовать за некачественный софт;</p>
                 <p>  Исправить можно за 5 минут (правка текста в конфиге).</p>
                 Итог: Технически пустяк (Low Severity), но бизнес-последствия катастрофичны → Срочно править! (High Priority).</p><br>
                 <p class="content-text">🛠 Пример 2: Высокая серьёзность (Severity) + Низкий приоритет (Priority)
                 <p>  Баг: В административной панели CRM при удалении архивного клиента падает ошибка 500, и его сделки не удаляются из базы.</p>
                 <p> Серьёзность (Severity): Critical (S2) Почему?</p>
                 <p> Критическая ошибка (падение сервера + некорректная работа с данными);</p>
                 <p>  Нарушена логика удаления;</p>
                 <p> Риск «захламления» базы неактуальными данными.</p>
                 <p> Приоритет (Priority): Low (P3) Почему?</p>
                 <p> Баг проявляется только в архиве, который не используется 2 года;</p>
                 <p> Функция удаления архивных клиентов отключена в интерфейсе (есть только прямой SQL-запрос);</p>
                 <p>  В следующем квартале архив будет полностью выведен из эксплуатации;</p>
                 <p> Все силы команды брошены на новый модуль онлайн-оплат (релиз через неделю).</p>
                 Итог: Технически опасная ошибка (High Severity), но в текущем контексте её исправление можно отложить (Low Priority).</p><br>
                 <p class="content-text">💎 Почему это работает?
                 <p> 1. Priority = Бизнес-логика + сроки Даже мелкий баг может стать «горящим», если мешает релизу, продажам или репутации.</p>
                 2. Severity = Технический ущерб Даже критичная ошибка может подождать, если она в заброшенном модуле, который скоро удалят.</p><br>
                 <p class="content-text">⚖️ Ещё экстремальные примеры:
                 <p> Ситуация	Серьёзность	Приоритет	Объяснение</p>
                 <p> Опечатка «Cбережения» → «Cбережения» в лендинге	Trivial (S5)	High (P1)	Запуск рекламной кампании на 1 млн$ завтра → все увидят ошибку.</p>
                 <p> Падение сервера в тестовой среде	Critical (S2)	Low (P3)	Продакшн работает стабильно, команда в отпуске → починим после каникул.</p>
                 Кнопка «Удалить Вселенную» в игре	Blocker (S1)	Medium (P2)	Баг в Easter egg, до которого добраться можно только через читы → не срочно.</p><br>
                 <p class="content-text">Главный вывод: Severity — это что сломалось, Priority — когда чинить в рамках бизнес-реальности. Умение их разделять — суперсила Senior QA!  </p><br>
                </div>
            </section>

            <!-- DevTools -->
            <section id="devtools" class="content-section">
                <h2 class="section-title">DevTools</h2>
                <div class="content-card">
                    <p class="content-text">DevTools (Developer Tools / Инструменты разработчика) — это встроенный в браузер набор инструментов для отладки, анализа и оптимизации веб-страниц.Это основной инструмент фронтенд-разработчиков и QA-инженеров при работе с веб-приложениями.</p>
                 <p class="content-text">DevTools — это твой набор инструментов, чтобы:
                 <p>1. Заглянуть ВНУТРЬ домика и посмотреть, как он устроен.</p>
                 <p>2. Починить или изменить что-то внутри, не ломая весь домик.</p>
                 <p>3. Увидеть, что происходит за стеной (между браузером и сервером).</p>
                 <p>Главные "инструменты" (вкладки) DevTools для тебя, без кода:</p>
                 <p>1. Элементы (Elements) — Твой Супер-Увеличитель для Внешнего Вида (HTML/CSS)</p>
                 <p>Что это: Как рентген или микроскоп для страницы. Показывает КАК сделан каждый кусочек сайта (текст, кнопка, картинка) и КАКИЕ у него "одежки" (цвет, размер, шрифт).</p>
                 <p> Как пользоваться (БЕЗ КОДА):</p>
                 <p> Открой DevTools (обычно F12 или Ctrl+Shift+I / Cmd+Opt+I).</p>
                 <p>Нажми иконку "Выбрать элемент" (часто стрелка в квадрате или курсор ▸ вверху слева) или просто Ctrl+Shift+C.</p>
                 <p>Наведи мышку на ЛЮБУЮ часть сайта (кнопку, картинку, текст) и кликни. В DevTools сразу подсветится "скелет" (HTML) этого элемента.</p>
                 <p>Справа увидишь "одежки" (стили CSS): Цвет (color), фон (background-color), размеры (width, height), отступы (margin, padding), шрифт (font-family, font-size).</p><br>
                 <p>Зачем тебе (QA):</p>
                 <p>Нашел баг? Криво стоит кнопка? Текст не того цвета? Кликни на проблемный элемент. Посмотри, какие стили к нему применены. Попробуй прямо тут отключить галочку рядом со стилем (например, margin-top: 10px;) — увидишь, как элемент "прыгнет". Включи обратно. Это поможет понять, в чем причина бага и точно описать ее разработчику: "У кнопки Submit слишком большой margin-top".</p>
                 <p>Проверить состояние: Наведись на элемент в списке слева (в HTML), нажми правую кнопку -> Force state -> выбери :hover или :focus. Увидишь, как элемент выглядит при наведении мышки или когда на нем фокус (например, подсветка кнопки). Не нужно двигать мышкой!</p>
                   Видишь скрытое? Иногда элемент есть на странице, но не виден (display: none). Найди его здесь — он будет сереньким. Кликни на него, и справа найди свойство display или visibility. Попробуй отключить display: none — элемент появится! Потом перезагрузи страницу (F5), и он снова скроется (изменения временные!).</p><br>
                 <p class="content-text">2. Сеть (Network) — Твой Детектор Переговоров (Запросы/Ответы)
                  Что это: Как рация, которая ловит ВСЕ разговоры между твоим браузером (клиентом) и сервером. Каждый раз, когда страница что-то загружает (картинку, данные для формы, список товаров) — это запрос и ответ.</p><br>
                 <p class="content-text">* Как пользоваться (БЕЗ КОДА):
               <p>ОЧЕНЬ ВАЖНО: Перейди на вкладку Network ДО того, как сделаешь действие (например, перед отправкой формы или обновлением страницы).</p>
                <p>Нажми кнопку "Очистить" (часто кружок с зачеркнутой линией), чтобы убрать старые записи.</p>
                 <p>Сделай действие: Нажми кнопку "Отправить", "Загрузить еще", обнови страницу (F5).</p>
               <p>Увидишь СПИСОК: Появятся строчки (запросы). Обычно самые важные для тестирования — это XHR или Fetch (данные, API).</p>
               <p>Кликни на строчку запроса.</p>
                <p> Смотри Headers: Это "паспорт" запроса. Тебе важно:</p>
                <p>   Status (Статус): 200 (ОК!), 404 (Не найдено), 500 (Ошибка сервера), 401 (Не залогинился). КРАСНЫЕ цифры (4xx, 5xx) = ОШИБКА! Самый важный показатель!</p>
                <p>   Request URL: Куда ушел запрос? Правильный адрес?</p>
                <p>   Method: GET (получить данные), POST (отправить данные). Правильный ли?</p>
                <p>Смотри Payload (если есть): Это "тело письма" — какие данные ты ОТПРАВИЛ на сервер (логин/пароль, текст комментария). Правильно ли ушли?</p>
                <p> Смотри Preview или Response: Это "ответное письмо" от сервера. Что он прислал обратно? Иногда там виден текст ошибки, если что-то пошло не так.</p>
                <p>Зачем тебе (QA):</p>
                <p> "Почему не отправилась форма?" Посмотри статус ответа. 500? Значит, ошибка на сервере. 401? Проверь авторизацию. Увидел ошибку в Response? Отлично, скопируй ее текст багрепорту.</p>
                <p>  "Правильные ли данные ушли?" Сравни то, что ввел в форму (Payload), с тем, что должно было уйти по ТЗ.</p>
                <p>  "Ничего не загружается?" Посмотри, есть ли вообще запросы? Может, страница пытается уйти не туда (Request URL неверный)? Все запросы красные?</p>
                 "Тормозит загрузка?" Посмотри на столбец Time или Size. Есть ли очень долгие или огромные запросы? (например, большая картинка или медленный запрос к API).</p><br>
                 <p class="content-text">3. Консоль (Console) — Твой Детектор Громких Ошибок (JavaScript)
                 <p>Что это: Как громкоговоритель, который кричит, если на сайте что-то сломалось в его "мозгах" (JavaScript). Или шепчет подсказки, которые оставили разработчики.</p>
                 <p>Как пользоваться (БЕЗ КОДА):</p>
                 <p>  Открой вкладку Console.</p>
                 <p>  Сразу смотри: Появились ли красные сообщения с текстом Error, Uncaught? Это КРИТИЧЕСКИЕ ошибки JavaScript. Они часто причина того, что "ничего не работает" или "кнопка не нажимается".</p>
                 <p>  Белый/серый текст: Это обычно информационные сообщения или логи разработчиков (console.log). Их можно пока игнорировать, если не ищешь что-то конкретное.</p><br>
                <p>Зачем тебе (QA):</p>
                <p>  Первое место проверки, если "ничего не работает". Увидел красную ошибку? Скопируй ее текст целиком и номер строки (он часто указан справа, например script.js:42). Это золото для разработчика! Говорит: "При нажатии на кнопку X в консоли красная ошибка: 'Cannot read property Y of undefined' (script.js:42)". Главная суперсила этой вкладки!</p>
                <p>  Понимание, что сломалось. Иногда текст ошибки сам подскажет: "Сетевая ошибка", "Не найден элемент", "Нет доступа".</p>
                 <p>4. Инструмент Адаптации (Device Toolbar) — Твой Магический Ресайзер</p>
                 <p> Что это: Волшебное зеркало, которое показывает, как сайт выглядит на телефоне, планшете или любом другом экране.</p>
                 <p>Как пользоваться (БЕЗ КОДА):</p>
                 <p>  Нажми иконку с телефоном/планшетом (📱) или Ctrl+Shift+M / Cmd+Shift+M.</p>
                 <p>  Выбери устройство из списка (iPhone, iPad, Samsung) или потяни за края окна браузера, чтобы задать свои размеры.</p>
                  <p>  Нажми "Rotate" (↻), чтобы повернуть экран (альбомный/книжный).</p><br>
                  <p>Зачем тебе (QA):</p>
                  <p>  Быстро проверить верстку на разных экранах. Уезжает ли меню? Криво стоят карточки товаров? Не видно важной кнопки? Не нужно реальных устройств под рукой!</p>
                  <p>  Эмуляция тача: Курсор мыши превращается в круг (как палец). Проверяй, удобно ли нажимать на кнопки.</p><br>
                   <p>Как это запомнить (супер-просто):</p>
                  <p>1. Выглядит криво? -> Лезу в Elements (смотрю стили, меняю их на лету).</p>
                  <p>2. Не работает кнопка/форма/загрузка? -> Первым делом смотрю в Console (ищу красные ошибки). Потом в Network (смотрю статусы ответов и что ушло/пришло).</p>
                   <p>3. Не пришли/неправильные данные? -> Только Network (смотрю Payload, Response, статусы).</p>
                  <p>4. Как на телефоне? -> Включаю Device Toolbar и выбираю устройство.</p>
	               5	Тормозит? -> Смотрю Network (долгие/тяжелые запросы).</p><br>
                </div>

                <h3 class="subsection-title">DevTools - вопросы</h3>
                <div class="content-card">
                    <p class="content-text">Что отображается на вкладке Elements?</p>
                 <p class="content-text">     На вкладке Elements отображается DOM-дерево страницы (все HTML-элементы).
                 <p>Позволяет выбирать и редактировать любые HTML-элементы на странице.</p>
                 <p>При выборе элемента на вкладке Styles отображаются все CSS правила, применяемые к нему (включая неактивные), упорядоченные по убыванию специфичности селектора. Их можно изменять, деактивировать и добавлять новые в реальном времени.</p>
                 <p>Для выбранного элемента доступны вкладки:</p>
                   <p>  Event Listeners: все события, относящиеся к элементу.</p>
                  <p>  DOM Breakpoints: точки останова для элемента.</p>
                   <p> Properties: список всех свойств элемента.</p>
                 Ключевые возможности (по статье): Просмотр/редактирование DOM и CSS в лайв-режиме, просмотр событий и свойств элемента.</p><br>
                 <p class="content-text">Какую полезную информацию мы можем увидеть во вкладке Console?
                  <p>Диагностическую информацию, которую разработчики логируют в процессе разработки (вывод console.log и других методов console).</p>
                   <p>Все ошибки JavaScript с указанием файла и конкретного места, где произошла ошибка.</p>
                  <p> XHR запросы (можно выводить в консоль).</p>
                  <p>Возможность взаимодействовать с JavaScript на странице (выполнять команды).</p>
                  Дополнительно (настройки): Фильтрация сообщений по типу или регулярному выражению, очистка логов (Clear console), сохранение логов между перезагрузками (Preserve log), сохранение логов в файл.</p><br>
                 <p class="content-text">Что полезного для тестировщика есть во вкладке Network?
                  <p> Мониторинг загрузки страницы и всех файлов: Полная таблица всех запросов (XHR, изображения, стили, скрипты и т.д.) к серверу.</p>
                  <p> Детали по каждому запросу: URL, метод (GET/POST/etc.), статус ответа (200, 404, 500 и т.д.), тип ресурса, источник (initiator), размер, время загрузки (включая детализацию по этапам: Waiting, Content Download и др.).</p>
                  <p> Общая статистика: Количество запросов, общий объем загруженных данных, общее время загрузки, время построения DOM (DOMContentLoaded), время полной загрузки (Load).</p>
                 <p> Инструменты эмуляции:</p>
                 <p>  Disable cache: Отключение кэша браузера (чтобы всегда получать свежие файлы с сервера).</p>
                  <p>  Ограничение пропускной способности/Offline: Эмуляция медленного интернета или полного его отсутствия.</p>
                 <p>Фильтрация и поиск: Возможность отфильтровать запросы по типу (XHR, JS, CSS и т.д.) или найти конкретный запрос по URL или части URL.</p>
                 <p>Preserve log: Сохранение лога сетевых запросов при перезагрузке страницы.</p>
                  Для тестировщика это ключево: Проверка корректности запросов/ответов (статусы, данные), анализ производительности загрузки, выявление "битых" ссылок (404), проверка поведения при медленном интернете/офлайн, проверка кэширования.</p><br>
                 <p class="content-text">Зачем нужна вкладка Application?
                 <p> Инспектировать и управлять данными клиентского хранилища:</p>
                 <p>   Local Storage и Session Storage: Просмотр, добавление, изменение, удаление ключей и значений.</p>
                   <p>   Cookies: Просмотр всех кук для текущего домена (имя, значение, домен, путь, срок действия, флаги HttpOnly/Secure), возможность их удаления.</p>
                   <p> IndexedDB / Web SQL: Просмотр баз данных, хранимых объектов, выполнение запросов (если поддерживается интерфейсом).</p>
                  <p> Просмотр кэша приложения (Application Cache / Cache Storage): Список закэшированных ресурсов.</p>
                  <p>Просмотр загруженных ресурсов: Изображения, шрифты, таблицы стилей (список файлов).</p>
                  <p> Быстрая очистка хранилищ: Возможность одним кликом очистить Local Storage, Session Storage, Cookies, Cache и т.д. (кнопки Clear site data или очистка в контекстном меню конкретного хранилища).</p>
                   Основная цель: Управление данными, которые сайт сохраняет в браузере пользователя, и очистка этих данных для тестирования различных сценариев (например, поведения "первого посещения").</p><br>
                 <p class="content-text">Как мы можем переключиться на мобильную версию сайта?
                   <p> С помощью кнопки "Переключение в режим выбора устройств" (Toggle device toolbar) на панели Elements. Статья прямо указывает: "она пригодится при разработке адаптивных интерфейсов, мобильных версий сайтов или для тестирования страниц с разным разрешением монитора".</p>
                   Эта кнопка обычно выглядит как значок смартфона/планшета. Ее активация переключает вид страницы в эмулятор мобильного устройства, позволяет выбирать конкретные модели устройств или задавать произвольные разрешения, эмулировать сенсорное управление, поворот экрана и тип сети.</p><br>
                 <p class="content-text">Как думаешь, какую вкладку в Devtools мы всегда держим открытой во время функционального тестирования?
                  <p> Ответ (основанный на логике функционального тестирования и возможностях панелей, описанных в статье):</p>
                  <p> Console: Критически важна. Здесь появляются все JavaScript-ошибки, которые могут сломать функциональность, предупреждения о проблемах, а также выводятся сообщения, которые разработчики (или тестовые скрипты) могут сознательно логировать для отладки. Пропустить ошибку в консоли во время функционального теста - значит пропустить потенциальный баг.</p>
                  <p> Network: Очень часто открыта. Позволяет видеть, какие запросы отправляются/принимаются при выполнении действий (нажатие кнопок, отправка форм), проверять их корректность (статусы, данные в запросе/ответе), выявлять "битые" запросы (404, 500) или отсутствие ожидаемых запросов. Особенно важна при тестировании взаимодействия с бэкендом (AJAX/Fetch).</p>
                    Elements: Часто нужна. Для проверки корректности отображения интерфейса, изменения состояния элементов (классы, стили) в ответ на действия пользователя, поиска элементов по селекторам для скриншотного тестирования или проверки структуры DOM.</p><br>
                 <p class="content-text">Итог: Хотя все три (Console, Network, Elements) часто используются, панель Console является самой критичной для постоянного мониторинга во время функционального тестирования, так как ошибки JavaScript напрямую указывают на проблемы в работе функциональности страницы. Однако, в зависимости от конкретного тестируемого функционала, Network или Elements могут быть не менее важны в данный момент. Постоянно открытой всегда логичнее всего держать Console.</p><br>
                 <p class="content-text">Где во вкладке Network посмотреть, как долго выполнялся конкретный http-запрос? Тело запроса? Ответ на запрос?
                  <p>Время выполнения запроса (Timing): Кликните на нужный запрос в таблице. Откроется панель деталей справа или снизу. Перейдите на вкладку Timing. Здесь подробно показано время каждого этапа запроса (DNS Lookup, Connecting, TLS Handshake, Waiting (TTFB), Content Download). Общее время видно в колонке таблицы Time или в сумме этапов на вкладке Timing.</p>
                  <p> Тело запроса (Request Body): В панели деталей запроса перейдите на вкладку Headers. Прокрутите вниз до секции Request Payload или Form Data (в зависимости от типа запроса и данных). Здесь будет тело запроса (например, параметры POST-запроса в формате JSON или x-www-form-urlencoded).</p>
                 Ответ на запрос (Response): В панели деталей запроса перейдите на вкладку Response (чтобы увидеть "сырой" ответ, обычно текст/JSON/HTML) или на вкладку Preview (чтобы увидеть ответ в удобочитаемом формате, например, отформатированный JSON, изображение или HTML).</p><br>
                 <p class="content-text">Как очистить данные сайта через Devtools?
                 <p>Откройте панель Application.</p>
                <p> В левом сайдбаре найдите раздел Storage.</p>
                 <p>Нажмите кнопку Clear site data (Очистить данные сайта) вверху. Она выглядит как корзина 🗑️.</p>
                <p> Появится диалоговое окно. Галочками выберите, что именно хотите очистить (Cookies, Local Storage, Session Storage, IndexedDB, Cache Storage и т.д.). Обычно выбирают всё.</p>
                  <p> Нажмите кнопку Clear (Очистить).</p>
                  Альтернатива (не только в DevTools): Можно очистить данные для конкретного сайта в основных настройках браузера Chrome (chrome://settings/siteData).</p><br>
                 <p class="content-text">Как можно включить имитацию медленного интернета?
                  <p>Откройте панель Network.</p>
                  <p> Найдите выпадающий список с надписью No throttling (Ограничение пропускной способности) обычно вверху панели, рядом с кнопками фильтрации и Disable cache.</p>
                  <p>Кликните на него и выберите нужный профиль ограничения скорости, например:</p>
                  <p>    Slow 3G (Медленный 3G)</p>
                 <p>   Fast 3G (Быстрый 3G)</p>
                  Custom... (Настроить...) - для создания своего профиля с заданной скоростью скачивания (Download), загрузки (Upload) и задержкой (Latency).</p><br>
                 <p class="content-text">Что такое кэш и зачем он нужен? 
                  <p>Кэш браузера - это специальное хранилище на вашем компьютере/устройстве, куда браузер сохраняет копии файлов (изображений, CSS, JS, шрифтов, HTML-страниц), загруженных с посещаемых вами сайтов.</p>
                  Зачем он нужен: Основная цель - ускорить загрузку сайтов при повторном посещении. Вместо того чтобы снова скачивать все файлы с сервера (что занимает время и тратит трафик), браузер берет их из кэша, если они не изменились. Это экономит ресурсы и пользователя, и сервера.</p><br>
                 <p class="content-text">Что такое куки (cookies) и зачем они нужны?
                  <p> Куки (cookies) - это небольшие текстовые файлы, которые сайт сохраняет в вашем браузере при его посещении.</p>
                  <p> Зачем они нужны: Основные цели:</p>
                 <p>  Сессии и аутентификация: Хранение информации о том, что вы вошли на сайт (сессионные куки), чтобы вам не приходилось вводить логин/пароль на каждой странице.</p>
                  <p>  Персонализация: Сохранение ваших предпочтений на сайте (язык, тема оформления, регион, настройки).</p>
                    Отслеживание: (Часто вызывает вопросы приватности) Запоминание ваших действий на сайте (просмотренные товары) или между сайтами (рекламные сети) для показа релевантной рекламы или аналитики.</p><br>
                 <p class="content-text">Зачем тестировщику иногда нужно чистить кэш?  Тестировщику нужно чистить кэш (и куки/локальное хранилище) регулярно, чтобы:
                 <p> Тестировать поведение "первого посещения": Убедиться, что новый пользователь видит правильную страницу (приветствие, туториал, форму регистрации и т.д.), а не закэшированную версию для авторизованных.</p>
                 <p> Видеть актуальные версии файлов: Убедиться, что браузер загружает самую свежую версию CSS, JS, изображений с сервера, а не старую закэшированную. Это критично при проверке исправлений багов в коде или обновлений дизайна.</p>
                 <p> Воспроизводить ошибки, связанные с кэшем: Некоторые баги проявляются только при наличии определенных закэшированных данных или только при их отсутствии. Очистка кэша помогает локализовать причину.</p>
                 <p> Тестировать механизмы кэширования сайта: Проверить, правильно ли сайт отправляет заголовки, управляющие кэшированием (Cache-Control, ETag), и как браузер на них реагирует.</p>
                  Избежать ложных результатов тестов: Старые закэшированные данные могут маскировать реальное поведение сайта или создавать ложное впечатление, что что-то работает/не работает.</p><br>
               </div>

                <h3 class="subsection-title">DevTools - практика</h3>
                <div class="content-card">
                    <p class="content-text">Чистить кэш нужно — чтобы проверить поведение сайта «глазами нового пользователя» и избежать ложных результатов.</p>
                 <p class="content-text">Конкретные причины:
                 <p>1. Тестирование первой загрузки: — Убедиться, что новые пользователи видят актуальные стили, скрипты, изображения (не старые закэшированные версии). — Проверить корректность загрузки без кэша (например, не «поехала» ли вёрстка).</p>
                 <p>2. Проверка обновлений: — Разработчик исправил баг, но вы всё ещё видите старую версию файла (.css, .js) из кэша → очистка кэша покажет, реально ли исправление работает.</p>
                 <p>3. Отладка «странных» багов: — Например: «У меня работает, а у пользователя нет» → часто проблема в закэшированном битом файле.</p>
                 <p>4. Тестирование авторизации/сессий: — Кэш может сохранять старые данные (например, профиль пользователя), мешая проверить логику выхода/смены аккаунта.</p>
                 <p>Как проверить в DevTools (Network): — Поставь галочку ✅ Disable cache — браузер будет игнорировать кэш во время работы DevTools. — Или просто нажми Ctrl+F5 (Windows) / Cmd+Shift+R (Mac) — «жёсткая» перезагрузка страницы с очисткой кэша.</p>
                 <p>Итог:</p>
                   Чистка кэша = гарантия, что баг реальный, а не «призрак» из прошлой версии сайта 👻. Тестируешь так, как видит систему настоящий пользователь!</p><br>
                 <p class="content-text">Время выполнения запроса:
                 <p>Столбец Time (правая часть таблицы запросов) — показывает общее время от начала до конца запроса в миллисекундах (мс).</p>
                 <p>"Водопад" (Waterfall) — цветная полоска справа от запроса. Длина полоски = времени. Наведи курсор на полоску — увидишь детали (DNS, подключение, отправка, ожидание (TTFB), загрузка).</p>
                 <p>Тело запроса (что отправилось НА сервер):</p>
                 <p>Выбери нужный запрос (кликни на строку).</p>
                 <p> Перейди на вкладку Payload (для POST/PUT) или Query String Parameters (для GET — данные в URL).</p>
                 <p> Что там: Параметры, форматы данных (JSON, Form Data), файлы.</p>
                 <p>Ответ сервера (что пришло ОТ сервера):</p>
                 <p> Выбери нужный запрос (кликни на строку).</p>
                 <p>  Перейди на вкладку Response (сырой текст ответа) или Preview (удобное форматирование для JSON/HTML/изображений).</p>
                 <p> Что там: Данные (JSON, HTML, текст), ошибки, статус успеха/провала.</p>
                 <p>Итог в 3 шага:</p>
                 <p>1. Время: Столбец Time или Waterfall.</p>
                 <p>2. Тело запроса: Вкладка Payload / Query String.</p>
                    3. Ответ: Вкладка Response / Preview.</p><br>
                </div>
            </section>
        </main>

        <footer class="footer">
            <p>&copy; 2025 Тестирование ПО. Все права защищены.FAZLEK</p>
        </footer>
    </div>

    <script src="script.js"></script>
</body>
</html>